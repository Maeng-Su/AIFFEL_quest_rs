{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5401b3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "# Tensorflow가 활용할 GPU가 장착되어 있는지 확인해 봅니다.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ed3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building ResNet Block\n",
    "\n",
    "def build_resnet_block34(input_layer,\n",
    "                       num_cnn=3,\n",
    "                       channel_ls=[64, 64],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=2,\n",
    "                      ):\n",
    "    # 입력 레이어\n",
    "    inputs = input_layer\n",
    "    x = inputs\n",
    "\n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        for idx, (channel, kernel_size) in enumerate(zip(channel_ls, kernel_size_ls)):\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_conv{cnn_num+1}_{idx+1}'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            \n",
    "            if idx+1 >= len(channel_ls):\n",
    "                break\n",
    "            \n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "                \n",
    "        x = keras.layers.Add()([x, inputs])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fb1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building ResNet Block\n",
    "\n",
    "def build_resnet_block50(input_layer,\n",
    "                       num_cnn=3,\n",
    "                       channel_ls=[64, 64, 256],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=2,\n",
    "                      ):\n",
    "    # 입력 레이어\n",
    "    inputs = input_layer\n",
    "    inputs_conv = keras.layers.Conv2D(\n",
    "                                filters=channel_ls[-1],  # 2배로 증가\n",
    "                                kernel_size=(1, 1),       # 1×1 컨볼루션\n",
    "                                strides=1,\n",
    "                                padding='same',           # 패딩 유지\n",
    "                                kernel_initializer='he_normal'  # He 초기화\n",
    "                            )(inputs)\n",
    "    x = inputs\n",
    "\n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        for idx, (channel, kernel_size) in enumerate(zip(channel_ls, kernel_size_ls)):\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_conv{cnn_num+1}_{idx+1}'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            \n",
    "            if idx+1 >= len(channel_ls):\n",
    "                break\n",
    "            \n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "        \n",
    "        x = keras.layers.Add()([x, inputs_conv])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cf0cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 56, 56, 64)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_1 (Conv2D)         (None, 56, 56, 64)   36928       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 56, 64)   256         block2_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 56, 56, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_2 (Conv2D)         (None, 56, 56, 64)   36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         block2_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_1 (Conv2D)         (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         block2_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_2 (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         block2_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_1 (Conv2D)         (None, 56, 56, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         block2_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_2 (Conv2D)         (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         block2_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 223,104\n",
      "Trainable params: 222,336\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_input_layer = keras.layers.Input(shape=(56,56,64))\n",
    "resnet_block_output = build_resnet_block34(input_layer=resnet_input_layer,\n",
    "                       num_cnn=3,\n",
    "                       channel_ls=[64, 64],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=2,\n",
    "                      )\n",
    "\n",
    "model = keras.Model(inputs=resnet_input_layer, outputs=resnet_block_output)  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5001c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e359c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet34(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    \n",
    "    output = keras.layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=(7, 7),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_conv'\n",
    "            )(input_layer)\n",
    "    \n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    \n",
    "    output = keras.layers.MaxPooling2D(\n",
    "                pool_size=(3, 3),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_maxpool'\n",
    "            )(output)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    block_num=2\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_resnet_block34(input_layer=output,\n",
    "                       num_cnn=num_cnn,\n",
    "                       channel_ls=[channel, channel],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=block_num,\n",
    "                      )\n",
    "        \n",
    "        if i+1 >= len(num_cnn_list):\n",
    "            break\n",
    "        \n",
    "        output = keras.layers.Conv2D(\n",
    "                                filters=channel*2,  # 2배로 증가\n",
    "                                kernel_size=(1, 1),       # 1×1 컨볼루션\n",
    "                                strides=1,\n",
    "                                padding='same',           # 패딩 유지\n",
    "                                kernel_initializer='he_normal'  # He 초기화\n",
    "                            )(output)\n",
    "        block_num+=1\n",
    "        \n",
    "    output = keras.layers.AveragePooling2D(name='AveragePooling2D')(output)\n",
    "    output = keras.layers.Flatten()(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f719f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet50(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    \n",
    "    output = keras.layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=(7, 7),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_conv'\n",
    "            )(input_layer)\n",
    "    \n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    \n",
    "    output = keras.layers.MaxPooling2D(\n",
    "                pool_size=(3, 3),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_maxpool'\n",
    "            )(output)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    block_num=2\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_resnet_block50(input_layer=output,\n",
    "                       num_cnn=num_cnn,\n",
    "                       channel_ls=[channel, channel, channel*4],\n",
    "                       kernel_size_ls=[1, 3, 1],\n",
    "                       block_num=block_num,\n",
    "                      )\n",
    "        \n",
    "        if i+1 >= len(num_cnn_list):\n",
    "            break\n",
    "        \n",
    "        output = keras.layers.Conv2D(\n",
    "                                filters=channel*2,  # 2배로 증가\n",
    "                                kernel_size=(1, 1),       # 1×1 컨볼루션\n",
    "                                strides=1,\n",
    "                                padding='same',           # 패딩 유지\n",
    "                                kernel_initializer='he_normal'  # He 초기화\n",
    "                            )(output)\n",
    "        block_num+=1\n",
    "        \n",
    "    output = keras.layers.AveragePooling2D(name='AveragePooling2D')(output)\n",
    "    output = keras.layers.Flatten()(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a02670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "                is_50=False):\n",
    "    if not is_50:\n",
    "        return build_resnet34(input_shape=input_shape,\n",
    "              num_classes=num_classes)\n",
    "    \n",
    "    else:\n",
    "        return build_resnet50(input_shape=input_shape,\n",
    "              num_classes=num_classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc07043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv (Conv2D)            (None, 16, 16, 64)   9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         block1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block1_maxpool (MaxPooling2D)   (None, 8, 8, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_1 (Conv2D)         (None, 8, 8, 64)     36928       block1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 64)     256         block2_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 64)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_2 (Conv2D)         (None, 8, 8, 64)     36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 64)     256         block2_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 64)     0           batch_normalization_8[0][0]      \n",
      "                                                                 block1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 64)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_1 (Conv2D)         (None, 8, 8, 64)     36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         block2_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_2 (Conv2D)         (None, 8, 8, 64)     36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 64)     256         block2_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 64)     0           batch_normalization_10[0][0]     \n",
      "                                                                 block1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 64)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_1 (Conv2D)         (None, 8, 8, 64)     36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 64)     256         block2_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_2 (Conv2D)         (None, 8, 8, 64)     36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 64)     256         block2_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 64)     0           batch_normalization_12[0][0]     \n",
      "                                                                 block1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 64)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 8, 8, 128)    8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_1 (Conv2D)         (None, 8, 8, 128)    147584      conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         block3_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         block3_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 128)    0           batch_normalization_14[0][0]     \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_1 (Conv2D)         (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 128)    512         block3_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         block3_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_1 (Conv2D)         (None, 8, 8, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         block3_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         block3_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4_1 (Conv2D)         (None, 8, 8, 128)    147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 128)    512         block3_conv4_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         block3_conv4_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 128)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 256)    33024       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_1 (Conv2D)         (None, 8, 8, 256)    590080      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        block4_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        block4_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 256)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_1 (Conv2D)         (None, 8, 8, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 256)    1024        block4_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 256)    1024        block4_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 256)    0           batch_normalization_24[0][0]     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 256)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_1 (Conv2D)         (None, 8, 8, 256)    590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        block4_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        block4_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           batch_normalization_26[0][0]     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4_1 (Conv2D)         (None, 8, 8, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 256)    1024        block4_conv4_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 256)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        block4_conv4_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 256)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv5_1 (Conv2D)         (None, 8, 8, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        block4_conv5_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv5_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        block4_conv5_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 256)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv6_1 (Conv2D)         (None, 8, 8, 256)    590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 256)    1024        block4_conv6_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 256)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv6_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        block4_conv6_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 256)    0           batch_normalization_32[0][0]     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 256)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 512)    131584      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_1 (Conv2D)         (None, 8, 8, 512)    2359808     conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 512)    2048        block5_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 512)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_2 (Conv2D)         (None, 8, 8, 512)    2359808     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 512)    2048        block5_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 512)    0           batch_normalization_34[0][0]     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 512)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_1 (Conv2D)         (None, 8, 8, 512)    2359808     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 512)    2048        block5_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 512)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_2 (Conv2D)         (None, 8, 8, 512)    2359808     activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 512)    2048        block5_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 512)    0           batch_normalization_36[0][0]     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 512)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_1 (Conv2D)         (None, 8, 8, 512)    2359808     activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 512)    2048        block5_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 512)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_2 (Conv2D)         (None, 8, 8, 512)    2359808     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 512)    2048        block5_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 512)    0           batch_normalization_38[0][0]     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 512)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "AveragePooling2D (AveragePoolin (None, 4, 4, 512)    0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           AveragePooling2D[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           81930       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,936,842\n",
      "Trainable params: 22,921,610\n",
      "Non-trainable params: 15,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "resnet_34 = build_resnet(input_shape=(32,32,3))\n",
    "\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbda197",
   "metadata": {},
   "outputs": [],
   "source": [
    "del resnet_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2233e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv (Conv2D)            (None, 16, 16, 64)   9472        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 64)   256         block1_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block1_maxpool (MaxPooling2D)   (None, 8, 8, 64)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_1 (Conv2D)         (None, 8, 8, 64)     4160        block1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 64)     256         block2_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 64)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_2 (Conv2D)         (None, 8, 8, 64)     36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         block2_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 64)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_3 (Conv2D)         (None, 8, 8, 256)    16640       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 256)    1024        block2_conv1_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 256)    16640       block1_maxpool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 256)    0           batch_normalization_42[0][0]     \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 256)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_1 (Conv2D)         (None, 8, 8, 64)     16448       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         block2_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 64)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_2 (Conv2D)         (None, 8, 8, 64)     36928       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         block2_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_3 (Conv2D)         (None, 8, 8, 256)    16640       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 256)    1024        block2_conv2_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 256)    0           batch_normalization_45[0][0]     \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 256)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_1 (Conv2D)         (None, 8, 8, 64)     16448       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         block2_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_2 (Conv2D)         (None, 8, 8, 64)     36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         block2_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 64)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv3_3 (Conv2D)         (None, 8, 8, 256)    16640       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 256)    1024        block2_conv3_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 256)    0           batch_normalization_48[0][0]     \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 256)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 128)    32896       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_1 (Conv2D)         (None, 8, 8, 128)    16512       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 128)    512         block3_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 128)    512         block3_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 128)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_3 (Conv2D)         (None, 8, 8, 512)    66048       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 512)    2048        block3_conv1_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 512)    66048       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 512)    0           batch_normalization_51[0][0]     \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 512)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_1 (Conv2D)         (None, 8, 8, 128)    65664       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         block3_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         block3_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_3 (Conv2D)         (None, 8, 8, 512)    66048       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 512)    2048        block3_conv2_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 512)    0           batch_normalization_54[0][0]     \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 512)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_1 (Conv2D)         (None, 8, 8, 128)    65664       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         block3_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 128)    512         block3_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_3 (Conv2D)         (None, 8, 8, 512)    66048       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 512)    2048        block3_conv3_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 512)    0           batch_normalization_57[0][0]     \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 512)    0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4_1 (Conv2D)         (None, 8, 8, 128)    65664       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 128)    512         block3_conv4_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 128)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4_2 (Conv2D)         (None, 8, 8, 128)    147584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 128)    512         block3_conv4_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 128)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4_3 (Conv2D)         (None, 8, 8, 512)    66048       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 512)    2048        block3_conv4_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 8, 512)    0           batch_normalization_60[0][0]     \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 512)    0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 256)    131328      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_1 (Conv2D)         (None, 8, 8, 256)    65792       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        block4_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 256)    1024        block4_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 256)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_3 (Conv2D)         (None, 8, 8, 1024)   263168      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 1024)   4096        block4_conv1_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 1024)   263168      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_63[0][0]     \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 1024)   0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_1 (Conv2D)         (None, 8, 8, 256)    262400      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        block4_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 256)    1024        block4_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 256)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_3 (Conv2D)         (None, 8, 8, 1024)   263168      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 1024)   4096        block4_conv2_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_66[0][0]     \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 1024)   0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_1 (Conv2D)         (None, 8, 8, 256)    262400      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        block4_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 256)    1024        block4_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 256)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_3 (Conv2D)         (None, 8, 8, 1024)   263168      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 1024)   4096        block4_conv3_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_69[0][0]     \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 1024)   0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4_1 (Conv2D)         (None, 8, 8, 256)    262400      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        block4_conv4_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 256)    1024        block4_conv4_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 256)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4_3 (Conv2D)         (None, 8, 8, 1024)   263168      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 1024)   4096        block4_conv4_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_72[0][0]     \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 1024)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv5_1 (Conv2D)         (None, 8, 8, 256)    262400      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        block4_conv5_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv5_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 256)    1024        block4_conv5_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 256)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv5_3 (Conv2D)         (None, 8, 8, 1024)   263168      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 1024)   4096        block4_conv5_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_75[0][0]     \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 1024)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv6_1 (Conv2D)         (None, 8, 8, 256)    262400      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 256)    1024        block4_conv6_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 256)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv6_2 (Conv2D)         (None, 8, 8, 256)    590080      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 256)    1024        block4_conv6_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 256)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv6_3 (Conv2D)         (None, 8, 8, 1024)   263168      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 1024)   4096        block4_conv6_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_78[0][0]     \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 1024)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 512)    524800      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_1 (Conv2D)         (None, 8, 8, 512)    262656      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 512)    2048        block5_conv1_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 512)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_2 (Conv2D)         (None, 8, 8, 512)    2359808     activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 512)    2048        block5_conv1_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 512)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_3 (Conv2D)         (None, 8, 8, 2048)   1050624     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 2048)   8192        block5_conv1_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 2048)   1050624     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 8, 8, 2048)   0           batch_normalization_81[0][0]     \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_1 (Conv2D)         (None, 8, 8, 512)    1049088     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 512)    2048        block5_conv2_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 512)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_2 (Conv2D)         (None, 8, 8, 512)    2359808     activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 512)    2048        block5_conv2_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 512)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_3 (Conv2D)         (None, 8, 8, 2048)   1050624     activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 2048)   8192        block5_conv2_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 2048)   0           batch_normalization_84[0][0]     \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 2048)   0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_1 (Conv2D)         (None, 8, 8, 512)    1049088     activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 512)    2048        block5_conv3_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 512)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_2 (Conv2D)         (None, 8, 8, 512)    2359808     activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 512)    2048        block5_conv3_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 512)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_3 (Conv2D)         (None, 8, 8, 2048)   1050624     activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 2048)   8192        block5_conv3_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 2048)   0           batch_normalization_87[0][0]     \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 2048)   0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "AveragePooling2D (AveragePoolin (None, 4, 4, 2048)   0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32768)        0           AveragePooling2D[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           327690      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,868,746\n",
      "Trainable params: 22,823,306\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "resnet_50 = build_resnet(input_shape=(32,32,3), is_50=True)\n",
    "\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dc04fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del resnet_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129dfbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building ResNet Block\n",
    "\n",
    "def build_plainnet_block34(input_layer,\n",
    "                       num_cnn=3,\n",
    "                       channel_ls=[64, 64],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=2,\n",
    "                      ):\n",
    "    # 입력 레이어\n",
    "    inputs = input_layer\n",
    "    x = inputs\n",
    "\n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        for idx, (channel, kernel_size) in enumerate(zip(channel_ls, kernel_size_ls)):\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_conv{cnn_num+1}_{idx+1}'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            \n",
    "            if idx+1 >= len(channel_ls):\n",
    "                break\n",
    "            \n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "                \n",
    "#         x = keras.layers.Add()([x, inputs])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff04b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building ResNet Block\n",
    "\n",
    "def build_plainnet_block50(input_layer,\n",
    "                       num_cnn=3,\n",
    "                       channel_ls=[64, 64, 256],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=2,\n",
    "                      ):\n",
    "    # 입력 레이어\n",
    "    inputs = input_layer\n",
    "#     inputs_conv = keras.layers.Conv2D(\n",
    "#                                 filters=channel_ls[-1],  # 2배로 증가\n",
    "#                                 kernel_size=(1, 1),       # 1×1 컨볼루션\n",
    "#                                 strides=1,\n",
    "#                                 padding='same',           # 패딩 유지\n",
    "#                                 kernel_initializer='he_normal'  # He 초기화\n",
    "#                             )(inputs)\n",
    "    x = inputs\n",
    "\n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        for idx, (channel, kernel_size) in enumerate(zip(channel_ls, kernel_size_ls)):\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_conv{cnn_num+1}_{idx+1}'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            \n",
    "            if idx+1 >= len(channel_ls):\n",
    "                break\n",
    "            \n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "        \n",
    "#         x = keras.layers.Add()([x, inputs_conv])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6207198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet모델 자체를 생성하는 함수입니다.\n",
    "def build_plainnet34(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    \n",
    "    output = keras.layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=(7, 7),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_conv'\n",
    "            )(input_layer)\n",
    "    \n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    \n",
    "    output = keras.layers.MaxPooling2D(\n",
    "                pool_size=(3, 3),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_maxpool'\n",
    "            )(output)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    block_num=2\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_plainnet_block34(input_layer=output,\n",
    "                       num_cnn=num_cnn,\n",
    "                       channel_ls=[channel, channel],\n",
    "                       kernel_size_ls=[3, 3],\n",
    "                       block_num=block_num,\n",
    "                      )\n",
    "        \n",
    "        if i+1 >= len(num_cnn_list):\n",
    "            break\n",
    "        \n",
    "        output = keras.layers.Conv2D(\n",
    "                                filters=channel*2,  # 2배로 증가\n",
    "                                kernel_size=(1, 1),       # 1×1 컨볼루션\n",
    "                                strides=1,\n",
    "                                padding='same',           # 패딩 유지\n",
    "                                kernel_initializer='he_normal'  # He 초기화\n",
    "                            )(output)\n",
    "        block_num+=1\n",
    "        \n",
    "    output = keras.layers.AveragePooling2D(name='AveragePooling2D')(output)\n",
    "    output = keras.layers.Flatten()(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a061e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet모델 자체를 생성하는 함수입니다.\n",
    "def build_plainnet50(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    \n",
    "    output = keras.layers.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=(7, 7),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_conv'\n",
    "            )(input_layer)\n",
    "    \n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    \n",
    "    output = keras.layers.MaxPooling2D(\n",
    "                pool_size=(3, 3),\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                name=f'block1_maxpool'\n",
    "            )(output)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    block_num=2\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_plainnet_block50(input_layer=output,\n",
    "                       num_cnn=num_cnn,\n",
    "                       channel_ls=[channel, channel, channel*4],\n",
    "                       kernel_size_ls=[1, 3, 1],\n",
    "                       block_num=block_num,\n",
    "                      )\n",
    "        \n",
    "        if i+1 >= len(num_cnn_list):\n",
    "            break\n",
    "        \n",
    "        output = keras.layers.Conv2D(\n",
    "                                filters=channel*2,  # 2배로 증가\n",
    "                                kernel_size=(1, 1),       # 1×1 컨볼루션\n",
    "                                strides=1,\n",
    "                                padding='same',           # 패딩 유지\n",
    "                                kernel_initializer='he_normal'  # He 초기화\n",
    "                            )(output)\n",
    "        block_num+=1\n",
    "        \n",
    "    output = keras.layers.AveragePooling2D(name='AveragePooling2D')(output)\n",
    "    output = keras.layers.Flatten()(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1934b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plainnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "                is_50=False):\n",
    "\n",
    "    if not is_50:\n",
    "        return build_plainnet34(input_shape=input_shape,\n",
    "              num_classes=num_classes)\n",
    "    \n",
    "    else:\n",
    "        return build_plainnet50(input_shape=input_shape,\n",
    "              num_classes=num_classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951d94cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv (Conv2D)         (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_maxpool (MaxPooling2D (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv2_1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv2_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv3_1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv3_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         8320      \n",
      "_________________________________________________________________\n",
      "block3_conv1_1 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2_1 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3_1 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv4_1 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv4_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 256)         33024     \n",
      "_________________________________________________________________\n",
      "block4_conv1_1 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2_1 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3_1 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv4_1 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv4_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv5_1 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv5_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv6_1 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv6_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 512)         131584    \n",
      "_________________________________________________________________\n",
      "block5_conv1_1 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1_2 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2_1 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2_2 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3_1 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3_2 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "AveragePooling2D (AveragePoo (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                81930     \n",
      "=================================================================\n",
      "Total params: 22,936,842\n",
      "Trainable params: 22,921,610\n",
      "Non-trainable params: 15,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "plaainnet_34 = build_plainnet(input_shape=(32,32,3))\n",
    "\n",
    "plaainnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f950a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "del plaainnet_34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d37a876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv (Conv2D)         (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_maxpool (MaxPooling2D (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_1 (Conv2D)      (None, 8, 8, 64)          4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1_3 (Conv2D)      (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv2_1 (Conv2D)      (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv2_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv2_3 (Conv2D)      (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv3_1 (Conv2D)      (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv3_2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv3_3 (Conv2D)      (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "block3_conv1_1 (Conv2D)      (None, 8, 8, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1_3 (Conv2D)      (None, 8, 8, 512)         66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2_1 (Conv2D)      (None, 8, 8, 128)         65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv2_3 (Conv2D)      (None, 8, 8, 512)         66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3_1 (Conv2D)      (None, 8, 8, 128)         65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv3_3 (Conv2D)      (None, 8, 8, 512)         66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv4_1 (Conv2D)      (None, 8, 8, 128)         65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv4_2 (Conv2D)      (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv4_3 (Conv2D)      (None, 8, 8, 512)         66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 256)         131328    \n",
      "_________________________________________________________________\n",
      "block4_conv1_1 (Conv2D)      (None, 8, 8, 256)         65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1_3 (Conv2D)      (None, 8, 8, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv2_1 (Conv2D)      (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv2_3 (Conv2D)      (None, 8, 8, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv3_1 (Conv2D)      (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv3_3 (Conv2D)      (None, 8, 8, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv4_1 (Conv2D)      (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv4_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv4_3 (Conv2D)      (None, 8, 8, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv5_1 (Conv2D)      (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv5_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv5_3 (Conv2D)      (None, 8, 8, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv6_1 (Conv2D)      (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv6_2 (Conv2D)      (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv6_3 (Conv2D)      (None, 8, 8, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 8, 8, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 512)         524800    \n",
      "_________________________________________________________________\n",
      "block5_conv1_1 (Conv2D)      (None, 8, 8, 512)         262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1_2 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1_3 (Conv2D)      (None, 8, 8, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 8, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv2_1 (Conv2D)      (None, 8, 8, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2_2 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv2_3 (Conv2D)      (None, 8, 8, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 8, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv3_1 (Conv2D)      (None, 8, 8, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3_2 (Conv2D)      (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv3_3 (Conv2D)      (None, 8, 8, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 8, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "AveragePooling2D (AveragePoo (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                327690    \n",
      "=================================================================\n",
      "Total params: 21,472,266\n",
      "Trainable params: 21,426,826\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "plaainnet_50 = build_plainnet(input_shape=(32,32,3), is_50=True)\n",
    "\n",
    "plaainnet_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "956adc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del plaainnet_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52e0af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 40\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    \"\"\"이미지 크기를 일정하게 변환하는 전처리 함수\"\"\"\n",
    "    image = tf.image.resize(image, IMG_SIZE)  # ✅ 이미지 크기 조정\n",
    "    image = image / 255.0  # ✅ 0~1 사이로 정규화\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "954052e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b111ab51e0541fc84fbe73fc833ef05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab44210a40e4b6cad9485417156a141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cats_vs_dogs-train.tfrecord...:   0%|          | 0/23262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /aiffel/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: ((None, None, 3), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
    "\n",
    "ds_train, ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "ds_train = ds_train[0]\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cf1541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ `map()`을 사용하여 데이터 변환 적용\n",
    "ds_train = ds_train.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "967a907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23262"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = ds_info.splits['train'].num_examples\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd8718e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18609, 4653)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(num_samples * 0.8)\n",
    "test_size = num_samples - train_size  # 나머지 20%\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b4b3536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터 개수: 18609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 데이터 개수: 4653\n"
     ]
    }
   ],
   "source": [
    "ds_train_split = ds_train.take(train_size)  # 처음 80% 가져오기\n",
    "ds_test_split = ds_train.skip(train_size)   # 이후 20% 가져오기\n",
    "\n",
    "print(\"Train 데이터 개수:\", len(list(ds_train_split.as_numpy_iterator())))\n",
    "print(\"Test 데이터 개수:\", len(list(ds_test_split.as_numpy_iterator())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b1e758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 이미지 크기: (32, 224, 224, 3)\n",
      "Train 레이블: tf.Tensor([1 0 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Train 데이터셋\n",
    "ds_train = ds_train_split.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Test 데이터셋\n",
    "ds_test = ds_test_split.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 데이터셋 확인\n",
    "for image, label in ds_train.take(1):\n",
    "    print(\"Train 이미지 크기:\", image.shape)\n",
    "    print(\"Train 레이블:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd7d956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆕 새로운 모델 생성...\n",
      "📂 학습 이력 없음. 새로 시작합니다.\n",
      "Epoch 1/40\n",
      "225/582 [==========>...................] - ETA: 8:36 - loss: 7.7087 - accuracy: 0.5024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/582 [============>.................] - ETA: 7:49 - loss: 6.7650 - accuracy: 0.5006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/582 [============>.................] - ETA: 7:35 - loss: 6.5402 - accuracy: 0.5006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/582 [===============>..............] - ETA: 6:29 - loss: 5.6894 - accuracy: 0.5019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/582 [=================>............] - ETA: 5:19 - loss: 5.0306 - accuracy: 0.5034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/582 [=================>............] - ETA: 5:14 - loss: 4.9952 - accuracy: 0.5037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/582 [==================>...........] - ETA: 4:57 - loss: 4.8591 - accuracy: 0.5031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/582 [==========================>...] - ETA: 1:01 - loss: 3.6176 - accuracy: 0.5015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 899s 1s/step - loss: 3.4088 - accuracy: 0.5014\n",
      "Epoch 2/40\n",
      "225/582 [==========>...................] - ETA: 8:34 - loss: 0.6947 - accuracy: 0.5089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/582 [============>.................] - ETA: 7:47 - loss: 0.6952 - accuracy: 0.5052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/582 [=============>................] - ETA: 7:27 - loss: 0.6951 - accuracy: 0.5063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/582 [===============>..............] - ETA: 6:27 - loss: 0.6952 - accuracy: 0.5076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/582 [=================>............] - ETA: 5:18 - loss: 0.6950 - accuracy: 0.5101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366/582 [=================>............] - ETA: 5:12 - loss: 0.6949 - accuracy: 0.5105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/582 [==================>...........] - ETA: 4:51 - loss: 0.6949 - accuracy: 0.5091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/582 [==========================>...] - ETA: 1:03 - loss: 0.6952 - accuracy: 0.5051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 842s 1s/step - loss: 0.6951 - accuracy: 0.5045\n",
      "Epoch 3/40\n",
      "222/582 [==========>...................] - ETA: 8:31 - loss: 0.6951 - accuracy: 0.5110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/582 [============>.................] - ETA: 7:40 - loss: 0.6956 - accuracy: 0.5084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/582 [=============>................] - ETA: 7:20 - loss: 0.6956 - accuracy: 0.5059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/582 [===============>..............] - ETA: 6:20 - loss: 0.6954 - accuracy: 0.5062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/582 [=================>............] - ETA: 5:10 - loss: 0.6953 - accuracy: 0.5076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/582 [=================>............] - ETA: 5:03 - loss: 0.6953 - accuracy: 0.5076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/582 [==================>...........] - ETA: 4:49 - loss: 0.6953 - accuracy: 0.5073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539/582 [==========================>...] - ETA: 1:01 - loss: 0.6955 - accuracy: 0.5035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 827s 1s/step - loss: 0.6955 - accuracy: 0.5033\n",
      "Epoch 4/40\n",
      "110/582 [====>.........................] - ETA: 11:12 - loss: 0.6953 - accuracy: 0.5082"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# 저장할 파일 경로\n",
    "CHECKPOINT_PATH = \"plaainnet_34_checkpoint.h5\"\n",
    "HISTORY_PATH = \"plaainnet_34_history.pkl\"\n",
    "\n",
    "# 저장된 체크포인트가 있으면 로드\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(\"🔄 기존 모델 불러오는 중...\")\n",
    "    model = tf.keras.models.load_model(CHECKPOINT_PATH)\n",
    "else:\n",
    "    print(\"🆕 새로운 모델 생성...\")\n",
    "    model = build_plainnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=2,\n",
    "                is_50=False)\n",
    "\n",
    "start_epoch = 0\n",
    "# 저장된 학습 히스토리 불러오기\n",
    "if os.path.exists(HISTORY_PATH):\n",
    "    print(\"📂 학습 이력 로드 중...\")\n",
    "    with open(HISTORY_PATH, 'rb') as f:\n",
    "        history_data = pickle.load(f)\n",
    "    start_epoch = history_data[\"epoch\"]\n",
    "    history = history_data[\"history\"]\n",
    "else:\n",
    "    print(\"📂 학습 이력 없음. 새로 시작합니다.\")\n",
    "    start_epoch = 0\n",
    "    history = {\"loss\": [], \"accuracy\": []}\n",
    "\n",
    "# 체크포인트 콜백 설정\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    CHECKPOINT_PATH, save_best_only=False, save_weights_only=False\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# 추가 학습할 에포크 설정\n",
    "history_obj = model.fit(\n",
    "    ds_train,\n",
    "    initial_epoch=start_epoch,  # 이어서 학습\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "# 학습 이력 저장\n",
    "history[\"loss\"].extend(history_obj.history[\"loss\"])\n",
    "history[\"accuracy\"].extend(history_obj.history[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HISTORY_PATH, 'wb') as f:\n",
    "    pickle.dump({\"epoch\": start_epoch + EPOCHS, \"history\": history}, f)\n",
    "\n",
    "# 학습 곡선 그리기\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history[\"loss\"], label=\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "223/582 [==========>...................] - ETA: 8:22 - loss: 3.6775 - accuracy: 0.5013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/582 [============>.................] - ETA: 7:31 - loss: 3.2635 - accuracy: 0.4988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/582 [============>.................] - ETA: 7:14 - loss: 3.1498 - accuracy: 0.4985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/582 [===============>..............] - ETA: 6:12 - loss: 2.8070 - accuracy: 0.5003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/582 [=================>............] - ETA: 5:03 - loss: 2.5228 - accuracy: 0.5015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "365/582 [=================>............] - ETA: 5:02 - loss: 2.5178 - accuracy: 0.5014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/582 [==================>...........] - ETA: 4:39 - loss: 2.4413 - accuracy: 0.5007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540/582 [==========================>...] - ETA: 58s - loss: 1.9274 - accuracy: 0.4986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - ETA: 0s - loss: 1.8395 - accuracy: 0.4978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 966s 2s/step - loss: 1.8395 - accuracy: 0.4978 - val_loss: 0.7404 - val_accuracy: 0.5012\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74043, saving model to plaainnet_34_checkpoint.h5\n",
      "Epoch 2/40\n",
      "224/582 [==========>...................] - ETA: 8:12 - loss: 0.6961 - accuracy: 0.5073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/582 [============>.................] - ETA: 7:21 - loss: 0.6963 - accuracy: 0.5032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/582 [=============>................] - ETA: 7:04 - loss: 0.6963 - accuracy: 0.5035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/582 [===============>..............] - ETA: 6:04 - loss: 0.6960 - accuracy: 0.5053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/582 [=================>............] - ETA: 4:58 - loss: 0.6961 - accuracy: 0.5048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "366/582 [=================>............] - ETA: 4:57 - loss: 0.6960 - accuracy: 0.5050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/582 [==================>...........] - ETA: 4:39 - loss: 0.6961 - accuracy: 0.5044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/582 [==========================>...] - ETA: 56s - loss: 0.6959 - accuracy: 0.5012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.5013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 888s 2s/step - loss: 0.6959 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74043 to 0.69314, saving model to plaainnet_34_checkpoint.h5\n",
      "Epoch 3/40\n",
      "186/582 [========>.....................] - ETA: 9:04 - loss: 0.6952 - accuracy: 0.5077"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, monitor=\"val_loss\", save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "plaainnet_34 = build_plainnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=2,\n",
    "                is_50=False)\n",
    "\n",
    "plaainnet_34.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_plaainnet_34 = plaainnet_34.fit(\n",
    "    ds_train,\n",
    "#     steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "#     validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[lr_callback, checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=2,\n",
    "                is_50=False)\n",
    "\n",
    "resnet_34.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet_34 = resnet_34.fit(\n",
    "    ds_train,\n",
    "#     steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "#     validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_plaainnet_34.history['loss'], 'r')\n",
    "plt.plot(history_resnet_34.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['plaainnet_34', 'resnet_34'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61071b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_plaainnet_34.history['val_accuracy'], 'r')\n",
    "plt.plot(history_resnet_34.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['plaainnet_34', 'resnet_34'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36678202",
   "metadata": {},
   "outputs": [],
   "source": [
    "plaainnet_50 = build_plainnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=2,\n",
    "                is_50=True)\n",
    "\n",
    "plaainnet_50.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_plaainnet_50 = plaainnet_50.fit(\n",
    "    ds_train,\n",
    "#     steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "#     validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = build_resnet(input_shape=(224,224,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=2,\n",
    "                is_50=True)\n",
    "\n",
    "resnet_50.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet_50 = resnet_50.fit(\n",
    "    ds_train,\n",
    "#     steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "#     validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_plaainnet_50.history['loss'], 'r')\n",
    "plt.plot(history_resnet_50.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['plaainnet_50', 'resnet_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_plaainnet_50.history['val_accuracy'], 'r')\n",
    "plt.plot(history_resnet_50.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['plaainnet_50', 'resnet_50'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0de5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
