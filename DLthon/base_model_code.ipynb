{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 불러오기\n",
    "\n",
    "train_path = './data/train.csv' # 필요에 따라 변경하세요.\n",
    "test_path = './data/test.csv' # 필요에 따라 변경하세요.\n",
    "train_normal_data_path = './data/일반대화 합성데이터(GPT-4o, AIhub 참고).csv'\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = load_data(train_path)\n",
    "test_df = load_data(test_path)\n",
    "normal_df = load_data(train_normal_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3950, 3), (500, 2), (1000, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "train_df.shape, test_df.shape, normal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      class                                       conversation\n",
       "0      0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1      1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2      2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3      3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4      4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 와 normal 데이터 합치기\n",
    "def concat_train_normal(train_df, normal_df):\n",
    "    train_df = pd.concat([train_df, normal_df], ignore_index=True)\n",
    "    train_df.drop(['idx'], axis=1, inplace=True)\n",
    "    train_df.reset_index(inplace=True)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "train_df = concat_train_normal(train_df, normal_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      class                                       conversation  \\\n",
       "0      0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
       "1      1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
       "2      2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
       "3      3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
       "4      4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
       "\n",
       "   class_encoded  \n",
       "0              0  \n",
       "1              0  \n",
       "2              3  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 숫자로 변환\n",
    "def class_encoding(train_df, class_mapping):\n",
    "    train_df['class_encoded'] = train_df['class'].replace(class_mapping)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 클래스 매핑 딕셔너리 정의\n",
    "class_mapping = {\n",
    "    \"협박 대화\": 0,\n",
    "    \"갈취 대화\": 1,\n",
    "    \"직장 내 괴롭힘 대화\": 2,\n",
    "    \"기타 괴롭힘 대화\": 3,\n",
    "    \"일반 대화\": 4\n",
    "}\n",
    "\n",
    "train_df = class_encoding(train_df, class_mapping)\n",
    "\n",
    "# 변환된 데이터 확인\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>4945</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>요즘 나는 축구 배워보고 싶다 키키\\n축구? 축구 룰에 대해서는 알아?\\n오오 알지...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>4946</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>프로게이머들은 좋아하는 거 하고 돈 버니까 좋겠다 키키\\n부럽. 임요한 진짜 돈 많...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>4947</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>너는 해외여행 자주 다니는 편이야? 키키\\n아니. 비행기 타는 걸 안 좋아해서 해외...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>4948</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>겨울에 눈이 제발 적게 오면 좋겠다\\n나도 키키 어릴 땐 눈 오는 게 되게 좋아했었...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>4949</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>요즘은 비나 태풍이 한번 와도 피해가 큰 듯\\n어 ㅠㅠ 나는 아직 태풍 매미를 잊지...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  class                                       conversation  \\\n",
       "4945   4945  일반 대화  요즘 나는 축구 배워보고 싶다 키키\\n축구? 축구 룰에 대해서는 알아?\\n오오 알지...   \n",
       "4946   4946  일반 대화  프로게이머들은 좋아하는 거 하고 돈 버니까 좋겠다 키키\\n부럽. 임요한 진짜 돈 많...   \n",
       "4947   4947  일반 대화  너는 해외여행 자주 다니는 편이야? 키키\\n아니. 비행기 타는 걸 안 좋아해서 해외...   \n",
       "4948   4948  일반 대화  겨울에 눈이 제발 적게 오면 좋겠다\\n나도 키키 어릴 땐 눈 오는 게 되게 좋아했었...   \n",
       "4949   4949  일반 대화  요즘은 비나 태풍이 한번 와도 피해가 큰 듯\\n어 ㅠㅠ 나는 아직 태풍 매미를 잊지...   \n",
       "\n",
       "      class_encoded  \n",
       "4945              4  \n",
       "4946              4  \n",
       "4947              4  \n",
       "4948              4  \n",
       "4949              4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 개행 문자(\"\\n\")를 공백으로 변환\n",
    "  sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "    \n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # ?.!, 앞뒤로 공백 추가\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence) # 연속된 공백 한개의 공백으로\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z\\u1100-\\u11FF\\uAC00-\\uD7AF.,?!]\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...\n",
       "1       길동경찰서입니다 .  시   분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...\n",
       "2       너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...\n",
       "3       어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...\n",
       "4       저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 이 선크림 파는데 한 번 손등에...\n",
       "                              ...                        \n",
       "4945    요즘 나는 축구 배워보고 싶다 키키 축구 ? 축구 룰에 대해서는 알아 ? 오오 알지...\n",
       "4946    프로게이머들은 좋아하는 거 하고 돈 버니까 좋겠다 키키 부럽 . 임요한 진짜 돈 많...\n",
       "4947    너는 해외여행 자주 다니는 편이야 ? 키키 아니 . 비행기 타는 걸 안 좋아해서 해...\n",
       "4948    겨울에 눈이 제발 적게 오면 좋겠다 나도 키키 어릴 땐 눈 오는 게 되게 좋아했었는...\n",
       "4949    요즘은 비나 태풍이 한번 와도 피해가 큰 듯 어    나는 아직 태풍 매미를 잊지 ...\n",
       "Name: conversation, Length: 4950, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = train_df['conversation'].apply(preprocess_sentence)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(conversation, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8215\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 1998번째 질문 샘플: [7, 5, 202, 1007, 54, 86, 3536, 7989, 52, 558, 1, 35, 8, 243, 1373, 6, 19, 5949, 7989, 263, 8193, 8113, 8136, 209, 827, 181, 1, 7, 5, 1121, 4290, 13, 2471, 1, 24, 171, 5708, 1102, 18, 219, 43, 1373, 244, 1744, 214, 1, 1693, 1159, 5649, 1297, 3171, 3143, 102, 2, 9, 7, 5, 39, 1158, 693, 341, 236, 2726, 7989, 443, 1342, 17, 2207, 1, 606, 482, 296, 296, 62, 1, 39, 100, 267, 54, 1443, 2, 45, 1, 1788, 4805, 178, 1, 8, 39, 314, 1980, 30, 480, 133, 1, 6507, 1, 14, 2193, 1033, 63, 1, 8, 39, 78, 498, 1, 7029, 257, 100, 711, 6637, 169, 1, 82, 43, 52, 1517, 450, 4046, 938, 1, 39, 174, 3832, 1158, 693, 408, 848, 194, 7643, 1, 7, 4263, 7989, 52, 19, 518, 7, 2361, 4138, 7989, 204, 7301, 103, 1, 1198, 6, 8191, 8142, 8095, 1763, 71, 61, 4259, 2618, 28]\n"
     ]
    }
   ],
   "source": [
    "# 1998번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 1998번째 질문 샘플: {}'.format(tokenizer.encode(conversation[1998])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['너',\n",
       " '내가',\n",
       " '좋은',\n",
       " '말로',\n",
       " '할',\n",
       " '때',\n",
       " '빌린',\n",
       " '돈',\n",
       " '내놔',\n",
       " '.',\n",
       " '아니',\n",
       " '나',\n",
       " '아직',\n",
       " '월급이',\n",
       " '안',\n",
       " '들어와서',\n",
       " '여윳돈이',\n",
       " '없다구',\n",
       " '.',\n",
       " '너',\n",
       " '내가',\n",
       " '처음',\n",
       " '이러는',\n",
       " '거',\n",
       " '아니잖아',\n",
       " '.',\n",
       " '왜',\n",
       " '사람',\n",
       " '화나게',\n",
       " '하냐고',\n",
       " '너는',\n",
       " '내',\n",
       " '월급날',\n",
       " '모르잖아',\n",
       " '.',\n",
       " '알려줬는데도',\n",
       " '매일',\n",
       " '사람한테',\n",
       " '이럴거야',\n",
       " '?',\n",
       " '야',\n",
       " '너',\n",
       " '내가',\n",
       " '지금',\n",
       " '칼',\n",
       " '들고',\n",
       " '너네',\n",
       " '원룸',\n",
       " '앞으로',\n",
       " '간다',\n",
       " '!',\n",
       " '새끼야',\n",
       " '.',\n",
       " '어이',\n",
       " '친구',\n",
       " '살살해',\n",
       " '.',\n",
       " '지금',\n",
       " '그게',\n",
       " '사람이',\n",
       " '할',\n",
       " '소리야',\n",
       " '?',\n",
       " '야',\n",
       " '.',\n",
       " '전화',\n",
       " '끊어봐',\n",
       " '.',\n",
       " '나',\n",
       " '지금',\n",
       " '차',\n",
       " '돌려서',\n",
       " '가고',\n",
       " '있어',\n",
       " '.',\n",
       " '잠깐만',\n",
       " '.',\n",
       " '진짜',\n",
       " '오고',\n",
       " '있냐고',\n",
       " '.',\n",
       " '나',\n",
       " '지금',\n",
       " '못',\n",
       " '나가',\n",
       " '.',\n",
       " '여자친구랑',\n",
       " '있어',\n",
       " '그게',\n",
       " '뭔',\n",
       " '상관인데',\n",
       " '.',\n",
       " '나는',\n",
       " '내',\n",
       " '돈',\n",
       " '받으러',\n",
       " '가겠다고',\n",
       " '.',\n",
       " '지금',\n",
       " '주머니칼',\n",
       " '들고',\n",
       " '갈테니까',\n",
       " '알아서해',\n",
       " '.',\n",
       " '너',\n",
       " '죽일거야',\n",
       " '돈',\n",
       " '안',\n",
       " '주면',\n",
       " '너',\n",
       " '경찰',\n",
       " '신고하기',\n",
       " '전에',\n",
       " '곱게',\n",
       " '자',\n",
       " '.',\n",
       " '밤이',\n",
       " '깊었는데',\n",
       " '뭐',\n",
       " '하고',\n",
       " '지랄이냐',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 확인\n",
    "conversation[1998].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69, 51, 67, 44, 140]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 세기\n",
    "temp = list(map(lambda x : len(x.split()), conversation))\n",
    "temp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.font_manager:Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 시각화 - histplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH = 200 일때: 95.90 %\n",
      "MAX_LENGTH = 100 일때: 71.13 %\n",
      "MAX_LENGTH = 50 일때: 24.38 %\n"
     ]
    }
   ],
   "source": [
    "print(f'MAX_LENGTH = 200 일때: {np.array([True if x <= 200 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 100 일때: {np.array([True if x <= 100 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 50 일때: {np.array([True if x <= 50 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 100\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 초과하는 샘플은 데이터 자르기, 패딩\n",
    "def tokenize_and_filter(inputs):\n",
    "  tokenized_inputs = list()\n",
    "  \n",
    "  for sentence in inputs:\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tokenizer.encode(sentence)\n",
    "\n",
    "    # 최대 길이 200 까지만 데이터셋으로 사용\n",
    "    if len(sentence) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence)\n",
    "    \n",
    "    else:\n",
    "      tokenized_inputs.append(sentence[:MAX_LENGTH])\n",
    "  \n",
    "  # 최대 길이 200으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8215\n",
      "필터링 후의 대화 샘플 개수: 4950\n"
     ]
    }
   ],
   "source": [
    "conversation = tokenize_and_filter(conversation)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 대화 샘플 개수: {}'.format(len(conversation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 - transformer 인코딩 모델 밑바닥부터 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "# 멀티 헤드 어텐션 구현하기\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# 패딩 마스크 구현 함수\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 인코더 생성하기\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더만 구성하기\n",
    "def my_encoder(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"my_encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # Global Average Pooling 적용 (or Max Pooling 가능)\n",
    "  outputs = tf.keras.layers.GlobalMaxPooling1D()(enc_outputs)\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(256, activation=\"relu\", name='dense1')(outputs)\n",
    "  outputs = tf.keras.layers.Dense(128, activation=\"relu\", name='dense2')(outputs)\n",
    "  outputs = tf.keras.layers.Dense(units=5, activation=\"softmax\", name='outputs')(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3157248     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 256)          65792       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128)          32896       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            645         dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,256,581\n",
      "Trainable params: 3,256,581\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성하기\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = my_encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# EarlyStopping & ModelCheckpoint 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model\", monitor='val_loss', save_best_only=True, mode='max', verbose=1, save_format=\"tf\", save_weights_only=True)\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2970, Validation size: 990, Test size: 990\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 크기 확인\n",
    "dataset_size = len(conversation)  # 입력 데이터 개수\n",
    "train_size = int(0.6 * dataset_size)  # 80% 훈련 데이터\n",
    "val_size = int(0.2 * dataset_size)  # 10% 검증 데이터\n",
    "test_size = dataset_size - train_size - val_size  # 10% 테스트 데이터\n",
    "\n",
    "train_df\n",
    "\n",
    "# 데이터셋 생성\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# TensorFlow Dataset 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': conversation},  # 입력 데이터\n",
    "    {'outputs': train_df['class_encoded'].values}  # 출력 데이터 (라벨)\n",
    "))\n",
    "\n",
    "dataset = dataset.cache().shuffle(BUFFER_SIZE)\n",
    "\n",
    "# 데이터셋 분할\n",
    "train_dataset = dataset.take(train_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = dataset.skip(train_size).take(val_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = dataset.skip(train_size + val_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(f\"Train size: {train_size}, Validation size: {val_size}, Test size: {test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 6s 48ms/step - loss: 1.6823 - accuracy: 0.2155 - val_loss: 1.5991 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.59914, saving model to best_model\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.5681 - accuracy: 0.2875 - val_loss: 1.5215 - val_accuracy: 0.3515\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.59914\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.4722 - accuracy: 0.3623 - val_loss: 1.3705 - val_accuracy: 0.4465\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.59914\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.3315 - accuracy: 0.4064 - val_loss: 1.2060 - val_accuracy: 0.4606\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.59914\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.1646 - accuracy: 0.4862 - val_loss: 1.0534 - val_accuracy: 0.5646\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.59914\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.0653 - accuracy: 0.5347 - val_loss: 0.9583 - val_accuracy: 0.6333\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.59914\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.9838 - accuracy: 0.5855 - val_loss: 0.8046 - val_accuracy: 0.7131\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.59914\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.8309 - accuracy: 0.6902 - val_loss: 0.5964 - val_accuracy: 0.8111\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.59914\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.6153 - accuracy: 0.7811 - val_loss: 0.4929 - val_accuracy: 0.8232\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.59914\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.4908 - accuracy: 0.8226 - val_loss: 0.3241 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.59914\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.3477 - accuracy: 0.8785 - val_loss: 0.2384 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.59914\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.2653 - accuracy: 0.9135 - val_loss: 0.1434 - val_accuracy: 0.9545\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.59914\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.1907 - accuracy: 0.9380 - val_loss: 0.0967 - val_accuracy: 0.9737\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.59914\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.1936 - accuracy: 0.9354 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.59914\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0950 - accuracy: 0.9667 - val_loss: 0.0219 - val_accuracy: 0.9970\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.59914\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0628 - accuracy: 0.9771 - val_loss: 0.0291 - val_accuracy: 0.9919\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.59914\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0380 - accuracy: 0.9886 - val_loss: 0.0338 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.59914\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0513 - accuracy: 0.9811 - val_loss: 0.0170 - val_accuracy: 0.9939\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.59914\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.0565 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.59914\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.59914\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.59914\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.59914\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0018 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.59914\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0114 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.59914\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0610 - accuracy: 0.9778 - val_loss: 0.0444 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.59914\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.59914\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 5.9509e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.59914\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0141 - accuracy: 0.9943 - val_loss: 4.1193e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.59914\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.0064 - val_accuracy: 0.9970\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.59914\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 0.0132 - val_accuracy: 0.9939\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.59914\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.59914\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 9.5821e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.59914\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.0046 - val_accuracy: 0.9990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.59914\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7a3e77ecf9a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "EPOCHS = 100\n",
    "model.fit(train_dataset, \n",
    "          validation_data=val_dataset, \n",
    "          epochs=EPOCHS, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 19s 50ms/step - loss: 1.8795 - accuracy: 0.2387 - val_loss: 1.5610 - val_accuracy: 0.3081\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.56104, saving model to best_model\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.5444 - accuracy: 0.3178 - val_loss: 1.5427 - val_accuracy: 0.2949\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.56104\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.4569 - accuracy: 0.3704 - val_loss: 1.4371 - val_accuracy: 0.3364\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.56104\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.3007 - accuracy: 0.4263 - val_loss: 1.1867 - val_accuracy: 0.4222\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.56104\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.1608 - accuracy: 0.4697 - val_loss: 1.1278 - val_accuracy: 0.4535\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.56104\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.0977 - accuracy: 0.4963 - val_loss: 0.9985 - val_accuracy: 0.5677\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.56104\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 1.0226 - accuracy: 0.5626 - val_loss: 0.8798 - val_accuracy: 0.6929\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.56104\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.8730 - accuracy: 0.6663 - val_loss: 0.6847 - val_accuracy: 0.7747\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.56104\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.7043 - accuracy: 0.7431 - val_loss: 0.4756 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.56104\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.5073 - accuracy: 0.8323 - val_loss: 0.3163 - val_accuracy: 0.9010\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.56104\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.4044 - accuracy: 0.8505 - val_loss: 0.2306 - val_accuracy: 0.9354\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.56104\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.2872 - accuracy: 0.9013 - val_loss: 0.1539 - val_accuracy: 0.9545\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.56104\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.2005 - accuracy: 0.9387 - val_loss: 0.0962 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.56104\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.1524 - accuracy: 0.9485 - val_loss: 0.0354 - val_accuracy: 0.9919\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.56104\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0968 - accuracy: 0.9687 - val_loss: 0.0352 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.56104\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0813 - accuracy: 0.9737 - val_loss: 0.0383 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.56104\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0542 - accuracy: 0.9795 - val_loss: 0.0244 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.56104\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0367 - accuracy: 0.9889 - val_loss: 0.0198 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.56104\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.56104\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.56104\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.56104\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.56104\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.3025 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.56104\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.0712 - accuracy: 0.9771 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.56104\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 2s 37ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0144 - val_accuracy: 0.9960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.56104\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 학습 실행 (history 저장)\n",
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 학습 결과(history) 가져오기\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history.get('accuracy', history.history.get('acc'))  # 'accuracy' 또는 'acc' 키 확인\n",
    "val_acc = history.history.get('val_accuracy', history.history.get('val_acc'))  # 'val_accuracy' 또는 'val_acc' 키 확인\n",
    "\n",
    "# 에포크 값 생성\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Loss 그래프\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    649\n",
       "4    614\n",
       "1    586\n",
       "2    577\n",
       "0    544\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in train_dataset:\n",
    "    X_train.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_train.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "pd.value_counts(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    213\n",
       "3    212\n",
       "1    198\n",
       "4    196\n",
       "0    171\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in val_dataset:\n",
    "    X_val.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_val.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "pd.value_counts(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.concatenate([X_train, X_val], axis=0)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3289, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(temp, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001823259750381112, 1.0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (train_dataset을 사용)\n",
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0025207968428730965, 0.9989898800849915]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (validation_dataset을 사용)\n",
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0018482889281585813, 1.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (train_dataset을 사용)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (990, 100)\n",
      "y_test shape: (990,)\n"
     ]
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 3, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pred(X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = get_pred(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       196\n",
      "           1     1.0000    1.0000    1.0000       218\n",
      "           2     1.0000    1.0000    1.0000       186\n",
      "           3     1.0000    1.0000    1.0000       214\n",
      "           4     1.0000    1.0000    1.0000       176\n",
      "\n",
      "    accuracy                         1.0000       990\n",
      "   macro avg     1.0000    1.0000    1.0000       990\n",
      "weighted avg     1.0000    1.0000    1.0000       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 Submission 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  target\n",
       "0  t_000       1\n",
       "1  t_001       2\n",
       "2  t_002       2\n",
       "3  t_003       2\n",
       "4  t_004       3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_submission_df(model, test_df):\n",
    "    test_conversation = test_df['text'].apply(preprocess_sentence)\n",
    "    test_conversation = tokenize_and_filter(test_conversation)\n",
    "    \n",
    "    y_pred = get_pred(test_conversation)\n",
    "    \n",
    "    test_df['target'] = y_pred\n",
    "    test_df.drop(['text'], axis=1, inplace=True)\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "test_df = make_submission_df(model, test_df)\n",
    "test_df.to_csv('my_submission.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 0, 1, 4, 0, 4, 1, 1, 2, 4, 4, 2, 2, 2, 2, 4, 1, 2, 3, 1,\n",
       "       2, 3, 2, 4, 1, 2, 4, 1, 3, 3, 0, 4, 3, 2, 0, 3, 1, 1, 2, 4, 0, 0,\n",
       "       4, 2, 1, 0, 0, 3, 0, 3, 4, 0, 4, 4, 4, 3, 1, 0, 3, 2, 3, 2, 2, 1,\n",
       "       3, 4, 0, 3, 1, 2, 0, 0, 4, 2, 3, 0, 0, 3, 4, 3, 3, 4, 4, 4, 2, 0,\n",
       "       4, 0, 4, 1, 3, 1, 1, 4, 1, 3, 4, 4, 0, 0, 3, 0, 2, 4, 0, 3, 0, 2,\n",
       "       0, 2, 1, 3, 1, 2, 1, 4, 3, 4, 1, 3, 1, 0, 4, 0, 1, 1, 3, 4, 3, 2,\n",
       "       0, 1, 2, 4, 2, 4, 4, 1, 3, 0, 3, 0, 3, 3, 1, 2, 3, 0, 4, 0, 2, 0,\n",
       "       0, 3, 0, 1, 0, 1, 4, 0, 0, 4, 2, 0, 4, 0, 0, 3, 0, 3, 4, 1, 3, 1,\n",
       "       2, 4, 3, 4, 3, 3, 0, 3, 1, 0, 1, 2, 4, 2, 4, 2, 1, 3, 1, 3, 4, 4,\n",
       "       1, 2, 1, 1, 3, 4, 1, 2, 3, 1, 1, 0, 3, 3, 3, 1, 4, 3, 4, 4, 4, 2,\n",
       "       3, 3, 2, 2, 3, 2, 3, 3, 1, 1, 3, 3, 1, 3, 4, 3, 0, 4, 4, 3, 4, 4,\n",
       "       1, 1, 1, 1, 4, 3, 0, 3, 1, 4, 4, 1, 2, 0, 4, 4, 4, 0, 1, 2, 1, 4,\n",
       "       2, 2, 2, 4, 1, 4, 3, 2, 4, 1, 2, 3, 2, 3, 4, 4, 2, 4, 3, 3, 2, 1,\n",
       "       3, 3, 1, 1, 1, 1, 3, 3, 3, 4, 3, 3, 1, 0, 3, 0, 3, 2, 3, 3, 3, 1,\n",
       "       1, 0, 1, 0, 1, 2, 2, 1, 2, 3, 1, 3, 3, 0, 0, 2, 2, 3, 0, 1, 1, 1,\n",
       "       3, 1, 4, 2, 0, 2, 4, 2, 2, 3, 2, 1, 0, 2, 3, 3, 4, 3, 1, 4, 2, 1,\n",
       "       4, 0, 3, 4, 4, 4, 3, 3, 3, 1, 2, 1, 0, 4, 4, 0, 1, 3, 1, 3, 1, 0,\n",
       "       2, 3, 0, 3, 0, 3, 1, 0, 3, 4, 3, 0, 1, 1, 0, 1, 3, 1, 4, 0, 3, 3,\n",
       "       0, 4, 0, 2, 2, 1, 4, 4, 3, 2, 4, 2, 3, 2, 0, 3, 0, 0, 2, 3, 2, 1,\n",
       "       2, 0, 3, 0, 4, 0, 1, 0, 2, 3, 1, 1, 1, 0, 4, 0, 3, 0, 4, 3, 0, 2,\n",
       "       1, 3, 2, 2, 3, 0, 4, 4, 3, 0, 4, 4, 2, 0, 2, 1, 1, 2, 3, 0, 3, 4,\n",
       "       2, 4, 3, 4, 1, 0, 2, 1, 0, 0, 3, 4, 4, 4, 3, 0, 4, 3, 4, 3, 3, 1,\n",
       "       0, 2, 0, 1, 3, 1, 2, 2, 1, 4, 3, 4, 4, 0, 0, 1, 0, 2, 2, 4, 0, 4,\n",
       "       4, 1, 4, 2, 4, 1, 4, 2, 3, 4, 3, 4, 0, 4, 3, 3, 0, 3, 3, 1, 3, 0,\n",
       "       2, 3, 1, 0, 0, 3, 1, 3, 3, 0, 2, 1, 1, 2, 0, 0, 1, 3, 4, 3, 3, 3,\n",
       "       3, 4, 2, 1, 4, 2, 3, 4, 3, 0, 3, 1, 2, 0, 0, 0, 3, 2, 4, 4, 3, 2,\n",
       "       1, 0, 4, 2, 2, 0, 4, 3, 2, 4, 1, 1, 0, 1, 4, 3, 4, 4, 4, 2, 0, 0,\n",
       "       4, 3, 4, 1, 0, 1, 1, 2, 3, 1, 2, 4, 0, 3, 3, 2, 4, 0, 3, 0, 3, 0,\n",
       "       0, 0, 3, 3, 1, 2, 3, 4, 3, 2, 0, 4, 3, 2, 2, 0, 2, 1, 2, 4, 1, 2,\n",
       "       3, 0, 2, 4, 1, 2, 3, 3, 0, 3, 3, 0, 2, 3, 1, 1, 3, 1, 0, 0, 2, 1,\n",
       "       3, 0, 1, 2, 4, 4, 2, 0, 2, 1, 4, 2, 0, 0, 1, 3, 0, 3, 3, 1, 3, 4,\n",
       "       3, 3, 0, 1, 2, 3, 2, 0, 2, 1, 3, 4, 3, 2, 1, 1, 1, 4, 2, 1, 0, 4,\n",
       "       3, 1, 0, 2, 4, 1, 4, 4, 0, 4, 0, 3, 3, 4, 1, 0, 4, 0, 1, 1, 4, 0,\n",
       "       3, 2, 1, 0, 3, 4, 4, 4, 2, 3, 4, 4, 0, 2, 0, 2, 4, 3, 3, 4, 4, 4,\n",
       "       4, 4, 3, 1, 4, 3, 4, 0, 3, 1, 1, 0, 3, 3, 4, 1, 4, 4, 2, 2, 2, 3,\n",
       "       0, 0, 4, 3, 0, 4, 3, 1, 3, 1, 0, 3, 3, 0, 4, 2, 0, 0, 2, 1, 4, 4,\n",
       "       1, 3, 3, 3, 1, 0, 4, 4, 3, 0, 3, 1, 1, 4, 1, 4, 2, 0, 2, 4, 0, 3,\n",
       "       1, 2, 2, 4, 4, 4, 1, 3, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 3, 1, 0,\n",
       "       4, 1, 2, 0, 2, 2, 4, 2, 4, 0, 4, 0, 2, 0, 0, 0, 2, 4, 0, 2, 3, 4,\n",
       "       4, 4, 4, 3, 2, 4, 1, 0, 4, 0, 2, 2, 1, 4, 4, 3, 2, 3, 0, 0, 1, 0,\n",
       "       1, 3, 0, 1, 3, 3, 1, 2, 2, 0, 2, 0, 2, 2, 4, 2, 4, 1, 0, 2, 1, 2,\n",
       "       2, 2, 2, 2, 3, 1, 2, 0, 1, 0, 0, 2, 2, 4, 2, 1, 4, 3, 3, 0, 2, 4,\n",
       "       2, 2, 4, 0, 3, 3, 3, 4, 3, 2, 4, 0, 3, 2, 2, 2, 2, 1, 2, 0, 0, 3,\n",
       "       2, 1, 0, 1, 3, 0, 0, 3, 3, 2, 2, 0, 4, 3, 1, 4, 1, 2, 1, 0, 1, 2,\n",
       "       1, 3, 3, 3, 2, 4, 1, 2, 1, 1, 3, 1, 4, 1, 1, 2, 2, 0, 4, 2, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1094\n",
       "4    1000\n",
       "1     981\n",
       "2     979\n",
       "0     896\n",
       "Name: class_encoded, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1783/450339232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# test_dataset에서 inputs(X)와 outputs(y) 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# X 값 (입력 데이터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# y 값 (라벨 데이터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in train_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
