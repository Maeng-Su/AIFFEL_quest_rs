{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 불러오기\n",
    "\n",
    "train_path = './data/train.csv' # 필요에 따라 변경하세요.\n",
    "# test_path = './data/test.csv' # 필요에 따라 변경하세요.\n",
    "train_normal_data_path = './data/normal_raw_conversations.csv'\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = load_data(train_path)\n",
    "# test_df = load_data(test_path)\n",
    "normal_df = load_data(train_normal_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3950, 3), (2023, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "train_df.shape, normal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      class                                       conversation\n",
       "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 명랑 핫도그 먹어 봤어?\\n웅 먹은 지 한참 됐어\\n나 오늘 먹었는데 진짜 존...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 지금 자취하고 있어?\\n웅 자취비 장난 아님\\n키키 맞아,\\n나도 지금 서울살...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니는 차 멀미 안 해?\\n나 멀미는 없더라\\n너 있어?\\n나 진짜 장난 아니야\\n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 지금 회사에서 어떤 일 하고 있어?\\n나 코디하자나\\n스트레스 장난 아님\\n와...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 남동생이나 오빠 있엉?\\n아니\\n나 외동 키키 왜?\\n나는 언니 한 명 있는데...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                       conversation  class_encoded\n",
       "0  일반 대화  언니 명랑 핫도그 먹어 봤어?\\n웅 먹은 지 한참 됐어\\n나 오늘 먹었는데 진짜 존...              4\n",
       "1  일반 대화  언니 지금 자취하고 있어?\\n웅 자취비 장난 아님\\n키키 맞아,\\n나도 지금 서울살...              4\n",
       "2  일반 대화  언니는 차 멀미 안 해?\\n나 멀미는 없더라\\n너 있어?\\n나 진짜 장난 아니야\\n...              4\n",
       "3  일반 대화  언니 지금 회사에서 어떤 일 하고 있어?\\n나 코디하자나\\n스트레스 장난 아님\\n와...              4\n",
       "4  일반 대화  언니 남동생이나 오빠 있엉?\\n아니\\n나 외동 키키 왜?\\n나는 언니 한 명 있는데...              4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 명랑 핫도그 먹어 봤어?\\n웅 먹은 지 한참 됐어\\n나 오늘 먹었는데 진짜 존...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 지금 자취하고 있어?\\n웅 자취비 장난 아님\\n키키 맞아,\\n나도 지금 서울살...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니는 차 멀미 안 해?\\n나 멀미는 없더라\\n너 있어?\\n나 진짜 장난 아니야\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 지금 회사에서 어떤 일 하고 있어?\\n나 코디하자나\\n스트레스 장난 아님\\n와...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일반 대화</td>\n",
       "      <td>언니 남동생이나 오빠 있엉?\\n아니\\n나 외동 키키 왜?\\n나는 언니 한 명 있는데...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                       conversation\n",
       "0  일반 대화  언니 명랑 핫도그 먹어 봤어?\\n웅 먹은 지 한참 됐어\\n나 오늘 먹었는데 진짜 존...\n",
       "1  일반 대화  언니 지금 자취하고 있어?\\n웅 자취비 장난 아님\\n키키 맞아,\\n나도 지금 서울살...\n",
       "2  일반 대화  언니는 차 멀미 안 해?\\n나 멀미는 없더라\\n너 있어?\\n나 진짜 장난 아니야\\n...\n",
       "3  일반 대화  언니 지금 회사에서 어떤 일 하고 있어?\\n나 코디하자나\\n스트레스 장난 아님\\n와...\n",
       "4  일반 대화  언니 남동생이나 오빠 있엉?\\n아니\\n나 외동 키키 왜?\\n나는 언니 한 명 있는데..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df = normal_df[['class', 'conversation']]\n",
    "normal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 와 normal 데이터 합치기\n",
    "def concat_train_normal(df_list):\n",
    "    train_df = pd.concat(df_list, ignore_index=True)\n",
    "#     train_df.drop(['idx'], axis=1, inplace=True)\n",
    "    train_df.reset_index(inplace=True)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  idx      class                                       conversation\n",
       "0      0  0.0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1      1  1.0      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2      2  2.0  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3      3  3.0      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4      4  4.0      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = concat_train_normal([train_df, normal_df])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>5968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>미국은 백신 6-11세 권고한대\\n헐 어린애들 우찌되면 어떻게\\n아니\\n애기들이 맞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969</th>\n",
       "      <td>5969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>우리는 항상 다이어트 중!\\n맞아\\n1년 동안 계속\\n키키 다이어트 여친도 매년.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>5970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>치아 보험 들어야 하나\\n치아 보험 애매하당\\n치아 보험은 뭔가 ㅠㅠ\\n오빠는 벌써...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>5971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>당근에는 없는 게 없어...\\n맞아\\n아주 용이해 하하\\n당근 들어가면... 뭐든 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>5972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>오빠 야구 중계 좀\\n지금 현재 8회말 1–0\\n키키 지금 어떻게 되고 있나여 키키...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  idx  class                                       conversation\n",
       "5968   5968  NaN  일반 대화  미국은 백신 6-11세 권고한대\\n헐 어린애들 우찌되면 어떻게\\n아니\\n애기들이 맞...\n",
       "5969   5969  NaN  일반 대화  우리는 항상 다이어트 중!\\n맞아\\n1년 동안 계속\\n키키 다이어트 여친도 매년.....\n",
       "5970   5970  NaN  일반 대화  치아 보험 들어야 하나\\n치아 보험 애매하당\\n치아 보험은 뭔가 ㅠㅠ\\n오빠는 벌써...\n",
       "5971   5971  NaN  일반 대화  당근에는 없는 게 없어...\\n맞아\\n아주 용이해 하하\\n당근 들어가면... 뭐든 ...\n",
       "5972   5972  NaN  일반 대화  오빠 야구 중계 좀\\n지금 현재 8회말 1–0\\n키키 지금 어떻게 되고 있나여 키키..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5973, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5869, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop_duplicates(subset=['conversation'])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1573</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>박사원은 군대를 안갔다와서 일을 이따구로 하나?\\n아닙니다.\\n넌 진짜 할 줄 아는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>군대도 주 52시간 하나 키키\\n군인 복지 좀 줄여야 해 내 생각엔\\n키키 군인 복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2787</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>이 씨발놈 아직 정신 못차렸네\\n좋게 말로 하니까 말을 들어처먹질않네\\n미안해\\n몇...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>847</td>\n",
       "      <td>847.0</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>야 좋은말로 할때 놓고 가라\\n 이거 엄마가 사주신거에요\\n아니 그냥 빌리겠다고 빨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>** 행님 집에 왔음?\\n행님은 언제 오심?\\n행님 오늘 퇴근 늦을 거래\\n행님 오...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     idx        class  \\\n",
       "0   1573  1573.0  직장 내 괴롭힘 대화   \n",
       "1   5689     NaN        일반 대화   \n",
       "2   2787  2787.0        협박 대화   \n",
       "3    847   847.0        갈취 대화   \n",
       "4   5661     NaN        일반 대화   \n",
       "\n",
       "                                        conversation  \n",
       "0  박사원은 군대를 안갔다와서 일을 이따구로 하나?\\n아닙니다.\\n넌 진짜 할 줄 아는...  \n",
       "1  군대도 주 52시간 하나 키키\\n군인 복지 좀 줄여야 해 내 생각엔\\n키키 군인 복...  \n",
       "2  이 씨발놈 아직 정신 못차렸네\\n좋게 말로 하니까 말을 들어처먹질않네\\n미안해\\n몇...  \n",
       "3  야 좋은말로 할때 놓고 가라\\n 이거 엄마가 사주신거에요\\n아니 그냥 빌리겠다고 빨...  \n",
       "4  ** 행님 집에 왔음?\\n행님은 언제 오심?\\n행님 오늘 퇴근 늦을 거래\\n행님 오...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4697, 4), (586, 4), (586, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = train_df.iloc[:5869//10, ]\n",
    "test_df = train_df.iloc[5869//10:5869//10*2, ]\n",
    "train_df = train_df.iloc[5869//10*2:, ]\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 불러오기\n",
    "train_path1 = './augment data/augmented_inserted_text_data.csv' # 필요에 따라 변경하세요.\n",
    "# train_path2 = './augment data/augmented_replaced_text_data.csv' # 필요에 따라 변경하세요.\n",
    "# train_path3 = './augment data/raw_data.csv' # 필요에 따라 변경하세요.\n",
    "test_path = './data/test.csv' # 필요에 따라 변경하세요.\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df1 = load_data(train_path1)\n",
    "# train_df2 = load_data(train_path2)\n",
    "# train_df3 = load_data(train_path3)\n",
    "# test_df = load_data(test_path)\n",
    "# normal_df = load_data(train_normal_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_encoded</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "      <td>\" 준하야 넌 대가리가 왜이렇게 크냐? 내 머리가 뭐. 밥먹으면 대가리만 크냐 너는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "      <td>내가 지금 너 아들 김길준을 데리고 있어. 살리고 싶으면 계좌에 1억만 더 더 보내...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "      <td>나는 씨 같은 사람 보면 참 신기하더라. 어떻게 또 그렇게 저렇게 살지. 너 왜 그...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "      <td>누구맘대로 여기서 장사하래? 이게 무슨일입니까? 남의 구역에서 장사하려면 자릿세를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "      <td>희정씨. 네 네? 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요? 손이 빤짝빤짝 네일했...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class  class_encoded  \\\n",
       "3841    기타 괴롭힘 대화              3   \n",
       "3842        갈취 대화              1   \n",
       "3843  직장 내 괴롭힘 대화              2   \n",
       "3844        갈취 대화              1   \n",
       "3845  직장 내 괴롭힘 대화              2   \n",
       "\n",
       "                                           conversation  \n",
       "3841  \" 준하야 넌 대가리가 왜이렇게 크냐? 내 머리가 뭐. 밥먹으면 대가리만 크냐 너는...  \n",
       "3842  내가 지금 너 아들 김길준을 데리고 있어. 살리고 싶으면 계좌에 1억만 더 더 보내...  \n",
       "3843  나는 씨 같은 사람 보면 참 신기하더라. 어떻게 또 그렇게 저렇게 살지. 너 왜 그...  \n",
       "3844  누구맘대로 여기서 장사하래? 이게 무슨일입니까? 남의 구역에서 장사하려면 자릿세를 ...  \n",
       "3845  희정씨. 네 네? 주말에 시간이 넘쳐나나봐 갑자기 왜그러세요? 손이 빤짝빤짝 네일했...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df1 = train_df1[~(train_df1['class_encoded']==4)]\n",
    "train_df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8543, 6),\n",
       "    level_0   index     idx        class  \\\n",
       " 0        0  2292.0  2292.0    기타 괴롭힘 대화   \n",
       " 1        1  5516.0     NaN        일반 대화   \n",
       " 2        2  1799.0  1799.0        협박 대화   \n",
       " 3        3  4468.0     NaN        일반 대화   \n",
       " 4        4   334.0   334.0  직장 내 괴롭힘 대화   \n",
       " \n",
       "                                         conversation  class_encoded  \n",
       " 0  야 너 이리와봐\\n응? 왜?\\n너 그 안경 뭐냐?\\n왜.? 이상해?\\n어 존나 이상...            NaN  \n",
       " 1  정신 건강은 눈빛에서 나와\\n눈빛이 아주 중요하지\\n키키 맞음...\\n지치면 눈빛이...            NaN  \n",
       " 2  지금 주소를 보낼테니 당장 내가 있는 곳으로 와.\\n 싫어. 지금 장난해? 내가 거...            NaN  \n",
       " 3  전세 사기 당했다고?\\n전세 사기 누구!?\\n맞아 아까 그거 뭐야?\\n그 ** 언니...            NaN  \n",
       " 4  오늘까지 자료 좀 찾아줘\\n 자료요? 어떤 자료 말씀이시죠? 아까 말씀하신 자료는 ...            NaN  )"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = concat_train_normal([train_df, train_df1])\n",
    "train_df.shape, train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8543, 2), (586, 2), (586, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['conversation', 'class']]\n",
    "val_df = val_df[['conversation', 'class']]\n",
    "test_df = test_df[['conversation', 'class']]\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8543, 3), (586, 3), (586, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 숫자로 변환\n",
    "def class_encoding(train_df, class_mapping):\n",
    "    train_df['class_encoded'] = train_df['class'].replace(class_mapping)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 클래스 매핑 딕셔너리 정의\n",
    "class_mapping = {\n",
    "    \"협박 대화\": 0,\n",
    "    \"갈취 대화\": 1,\n",
    "    \"직장 내 괴롭힘 대화\": 2,\n",
    "    \"기타 괴롭힘 대화\": 3,\n",
    "    \"일반 대화\": 4\n",
    "}\n",
    "\n",
    "train_df = class_encoding(train_df, class_mapping)\n",
    "val_df = class_encoding(val_df, class_mapping)\n",
    "test_df = class_encoding(test_df, class_mapping)\n",
    "\n",
    "# 변환된 데이터 확인\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>야 너 이리와봐\\n응? 왜?\\n너 그 안경 뭐냐?\\n왜.? 이상해?\\n어 존나 이상...</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정신 건강은 눈빛에서 나와\\n눈빛이 아주 중요하지\\n키키 맞음...\\n지치면 눈빛이...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지금 주소를 보낼테니 당장 내가 있는 곳으로 와.\\n 싫어. 지금 장난해? 내가 거...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>전세 사기 당했다고?\\n전세 사기 누구!?\\n맞아 아까 그거 뭐야?\\n그 ** 언니...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>오늘까지 자료 좀 찾아줘\\n 자료요? 어떤 자료 말씀이시죠? 아까 말씀하신 자료는 ...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>너 바람피는거 다 알고 있어\\n 어떤 근거로 그러시는거죠?\\n 너 바람피는 현장을 ...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>너는 남자친구에 대한 환상이 있어?\\n이상형이 어떻게 돼?\\n나는 예의만 바르면 다...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>돼지야 너 돼지잖아. 돼지야 오늘 꿀꿀소리 내가 따줄게\\n갑자기? 왜. 우리 그동안...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>나 틴트 한번만 빌려줄 수 있어?\\n 아 틴트 같이 쓰면 안좋대\\n 엥 그거 한번 ...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>운동화도 점점 비싸지지 않냐...\\n응 진짜 물가 뭐냐...\\n마즘...\\n20이 ...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation        class  \\\n",
       "0  야 너 이리와봐\\n응? 왜?\\n너 그 안경 뭐냐?\\n왜.? 이상해?\\n어 존나 이상...    기타 괴롭힘 대화   \n",
       "1  정신 건강은 눈빛에서 나와\\n눈빛이 아주 중요하지\\n키키 맞음...\\n지치면 눈빛이...        일반 대화   \n",
       "2  지금 주소를 보낼테니 당장 내가 있는 곳으로 와.\\n 싫어. 지금 장난해? 내가 거...        협박 대화   \n",
       "3  전세 사기 당했다고?\\n전세 사기 누구!?\\n맞아 아까 그거 뭐야?\\n그 ** 언니...        일반 대화   \n",
       "4  오늘까지 자료 좀 찾아줘\\n 자료요? 어떤 자료 말씀이시죠? 아까 말씀하신 자료는 ...  직장 내 괴롭힘 대화   \n",
       "5  너 바람피는거 다 알고 있어\\n 어떤 근거로 그러시는거죠?\\n 너 바람피는 현장을 ...        협박 대화   \n",
       "6  너는 남자친구에 대한 환상이 있어?\\n이상형이 어떻게 돼?\\n나는 예의만 바르면 다...        일반 대화   \n",
       "7  돼지야 너 돼지잖아. 돼지야 오늘 꿀꿀소리 내가 따줄게\\n갑자기? 왜. 우리 그동안...        협박 대화   \n",
       "8  나 틴트 한번만 빌려줄 수 있어?\\n 아 틴트 같이 쓰면 안좋대\\n 엥 그거 한번 ...        갈취 대화   \n",
       "9  운동화도 점점 비싸지지 않냐...\\n응 진짜 물가 뭐냐...\\n마즘...\\n20이 ...        일반 대화   \n",
       "\n",
       "   class_encoded  \n",
       "0              3  \n",
       "1              4  \n",
       "2              0  \n",
       "3              4  \n",
       "4              2  \n",
       "5              0  \n",
       "6              4  \n",
       "7              0  \n",
       "8              1  \n",
       "9              4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박사원은 군대를 안갔다와서 일을 이따구로 하나?\\n아닙니다.\\n넌 진짜 할 줄 아는...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>군대도 주 52시간 하나 키키\\n군인 복지 좀 줄여야 해 내 생각엔\\n키키 군인 복...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이 씨발놈 아직 정신 못차렸네\\n좋게 말로 하니까 말을 들어처먹질않네\\n미안해\\n몇...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>야 좋은말로 할때 놓고 가라\\n 이거 엄마가 사주신거에요\\n아니 그냥 빌리겠다고 빨...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>** 행님 집에 왔음?\\n행님은 언제 오심?\\n행님 오늘 퇴근 늦을 거래\\n행님 오...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>민아야 나 방과후비 혹시 대신 내줄 수 있어?\\n갑자기? 안돼. 나 그 많은 돈 없...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>어이 거기!\\n네? 저요?\\n그럼 거기 너 말고 또 누구 있어? 이리 와봐.\\n왜 ...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>언니 요즘에 여자가 군대를 가야하냐 말아야 하냐 되게 이슈잖아!\\n웅 맞아\\n왜 군...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>나 오늘 카드값 얼마 내야 하는지 문자가 왔어,\\n아 그날이 제일 긴장되는 날이긴 ...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>어우 정대리 이번에도 참 글래머 스럽게 입고왔네\\n네? 지금 저한태 하신말이세요?\\...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation        class  \\\n",
       "0  박사원은 군대를 안갔다와서 일을 이따구로 하나?\\n아닙니다.\\n넌 진짜 할 줄 아는...  직장 내 괴롭힘 대화   \n",
       "1  군대도 주 52시간 하나 키키\\n군인 복지 좀 줄여야 해 내 생각엔\\n키키 군인 복...        일반 대화   \n",
       "2  이 씨발놈 아직 정신 못차렸네\\n좋게 말로 하니까 말을 들어처먹질않네\\n미안해\\n몇...        협박 대화   \n",
       "3  야 좋은말로 할때 놓고 가라\\n 이거 엄마가 사주신거에요\\n아니 그냥 빌리겠다고 빨...        갈취 대화   \n",
       "4  ** 행님 집에 왔음?\\n행님은 언제 오심?\\n행님 오늘 퇴근 늦을 거래\\n행님 오...        일반 대화   \n",
       "5  민아야 나 방과후비 혹시 대신 내줄 수 있어?\\n갑자기? 안돼. 나 그 많은 돈 없...        갈취 대화   \n",
       "6  어이 거기!\\n네? 저요?\\n그럼 거기 너 말고 또 누구 있어? 이리 와봐.\\n왜 ...        갈취 대화   \n",
       "7  언니 요즘에 여자가 군대를 가야하냐 말아야 하냐 되게 이슈잖아!\\n웅 맞아\\n왜 군...        일반 대화   \n",
       "8  나 오늘 카드값 얼마 내야 하는지 문자가 왔어,\\n아 그날이 제일 긴장되는 날이긴 ...        일반 대화   \n",
       "9  어우 정대리 이번에도 참 글래머 스럽게 입고왔네\\n네? 지금 저한태 하신말이세요?\\...  직장 내 괴롭힘 대화   \n",
       "\n",
       "   class_encoded  \n",
       "0              2  \n",
       "1              4  \n",
       "2              0  \n",
       "3              1  \n",
       "4              4  \n",
       "5              1  \n",
       "6              1  \n",
       "7              4  \n",
       "8              4  \n",
       "9              2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>위에 보고를 그딴식으로 하면 어떡해? 나 엿먹이려고 작정했어? 미친거아니야?\\n 그...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>푸핫 야 너 배좀 봐 밥이 들어가니?\\n아 왜그래요\\n아니 너만 보면 진짜 한심해서...</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>아무개씨 지금업무 다했어?\\n다 끝나갑니다\\n빨리빨리 안하고 느려터져서는\\n죄송합니...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>술 게임 재밋는데 ㅎ\\n라이어게임하고싶당\\n너 라이어 진짜 ㅜ 장해...\\n오 나 ...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>강아지 왜 안 키워?\\n강아지 털 알러지 때문에\\n냄새 마니 나자너\\n강아지는  사...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>자 이번 달 이벤트 아이디어 회의 좀 해보자구\\n팀장님! 저는 안을 생각해 봤는데요...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>너 이번 방학 때 쌍꺼풀 수술 하고왔지?\\n아닌데?\\n아니긴 뭐가 아니야. 눈이 이...</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>책임자 바꿔.\\n 아 고객님 저한테 말씀하시면.\\n 네가 뭘 안다고 그래?\\n 고객...</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>나 좀 건강한 듯\\n감기몸살 거의 다 나음\\n키키 그래 보이더라 풍채가 당당\\n피 ...</td>\n",
       "      <td>일반 대화</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>저기 김씨\\n 아 네 대표님 !\\n 혹시 주말에 시간 돼 ?\\n 네? 무슨일로 그러...</td>\n",
       "      <td>직장 내 괴롭힘 대화</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          conversation        class  \\\n",
       "586  위에 보고를 그딴식으로 하면 어떡해? 나 엿먹이려고 작정했어? 미친거아니야?\\n 그...        협박 대화   \n",
       "587  푸핫 야 너 배좀 봐 밥이 들어가니?\\n아 왜그래요\\n아니 너만 보면 진짜 한심해서...    기타 괴롭힘 대화   \n",
       "588  아무개씨 지금업무 다했어?\\n다 끝나갑니다\\n빨리빨리 안하고 느려터져서는\\n죄송합니...  직장 내 괴롭힘 대화   \n",
       "589  술 게임 재밋는데 ㅎ\\n라이어게임하고싶당\\n너 라이어 진짜 ㅜ 장해...\\n오 나 ...        일반 대화   \n",
       "590  강아지 왜 안 키워?\\n강아지 털 알러지 때문에\\n냄새 마니 나자너\\n강아지는  사...        일반 대화   \n",
       "591  자 이번 달 이벤트 아이디어 회의 좀 해보자구\\n팀장님! 저는 안을 생각해 봤는데요...  직장 내 괴롭힘 대화   \n",
       "592  너 이번 방학 때 쌍꺼풀 수술 하고왔지?\\n아닌데?\\n아니긴 뭐가 아니야. 눈이 이...    기타 괴롭힘 대화   \n",
       "593  책임자 바꿔.\\n 아 고객님 저한테 말씀하시면.\\n 네가 뭘 안다고 그래?\\n 고객...    기타 괴롭힘 대화   \n",
       "594  나 좀 건강한 듯\\n감기몸살 거의 다 나음\\n키키 그래 보이더라 풍채가 당당\\n피 ...        일반 대화   \n",
       "595  저기 김씨\\n 아 네 대표님 !\\n 혹시 주말에 시간 돼 ?\\n 네? 무슨일로 그러...  직장 내 괴롭힘 대화   \n",
       "\n",
       "     class_encoded  \n",
       "586              0  \n",
       "587              3  \n",
       "588              2  \n",
       "589              4  \n",
       "590              4  \n",
       "591              2  \n",
       "592              3  \n",
       "593              3  \n",
       "594              4  \n",
       "595              2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates(subset=['conversation'])\n",
    "train_df = train_df.sample(frac=1, random_state=None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8543, 3), (586, 3), (586, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 개행 문자(\"\\n\")를 공백으로 변환\n",
    "  sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "    \n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # ?.!, 앞뒤로 공백 추가\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence) # 연속된 공백 한개의 공백으로\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z\\u1100-\\u11FF\\uAC00-\\uD7AF.,?!]\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       여어 야 너 랑 만나지 ? 아 아 . 아 어 . 그렇게 안 됐어 . 하아 너 진짜 ...\n",
       "1       아파트에서 할로윈 파티 했음 . . . 그니까 여기 하더라 하하 키키 아 진짜 애기...\n",
       "2       여기가 어딘가요 ? 야 있는 돈 다 내놔 . 맞기 싫으면 아니 댁은 누구신대 다짜고...\n",
       "3       요즘 예능이 너무 재밌어 이번 년도 연예대상은 누가 받을까 무슨 예능이 요즘 대세니...\n",
       "4       핸드크림 바르시는 분 겨울에는 필수템이지   저여 안 그럼 다 갈라짐 . . . 핸...\n",
       "                              ...                        \n",
       "8538    출출하다 . 라면 먹어야지 저렇게 라면 먹으니깐 살찌지 아니 배고파서 먹는건데 그만...\n",
       "8539    어디서 자꾸 이상한 냄새 나 어디 ? ? ? 유리야 너 입에서 나는 것도 같아 내 ...\n",
       "8540    야 나 돈 좀 빌려주라 왜 ? 무슨일이야 ? 엄마가 아프신데 병원비 내야해 저번에도...\n",
       "8541    당장 우리 아들과 헤어져 어머님 저 정말 그이를 사랑해요 ! . 나는 가난한 사람과...\n",
       "8542    어이 이게 누구야 ? 네 돈 떼 먹고 두 다리 쫙 펴고 잘 살고 있었나 ? ? 어 ...\n",
       "Name: conversation, Length: 8543, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = train_df['conversation'].apply(preprocess_sentence)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(conversation, target_vocab_size=2**11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2039\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 1998번째 질문 샘플: [34, 388, 171, 2, 126, 937, 238, 405, 1120, 1815, 750, 77, 39, 538, 1573, 68, 1782, 1177, 787, 1815, 1504, 1815, 729, 37, 1512, 81, 179, 981, 485, 1411, 1683, 1815, 468, 924, 1815, 765, 707, 812, 151, 341, 804, 1815, 13, 28, 176, 89, 802, 1640, 10, 142, 16, 2, 49, 740, 1641, 1, 135, 835, 1815, 74, 1544, 487, 364, 37, 1000, 738, 1815, 464, 1004, 734, 81, 487, 1815, 48, 128, 1106, 1815, 784, 74, 812, 16, 1172, 314, 240, 1287, 731]\n"
     ]
    }
   ],
   "source": [
    "# 1998번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 1998번째 질문 샘플: {}'.format(tokenizer.encode(conversation[1998])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['왜',\n",
       " '이러세요',\n",
       " '?',\n",
       " '이거',\n",
       " '놓으세요',\n",
       " '가방',\n",
       " '이리내',\n",
       " '안',\n",
       " '그러면',\n",
       " '죽여버리겠어',\n",
       " '진정하세요',\n",
       " '드릴게요',\n",
       " '드리면',\n",
       " '되잖아요',\n",
       " '빨리',\n",
       " '내놔',\n",
       " '좋은',\n",
       " '말로',\n",
       " '할때',\n",
       " '여기있어요',\n",
       " '그만',\n",
       " '놔주세요',\n",
       " '드렸잖아요',\n",
       " '너',\n",
       " '나들마트',\n",
       " '옆에',\n",
       " '살지',\n",
       " '?',\n",
       " '아니',\n",
       " '그걸',\n",
       " '어떻게',\n",
       " '.',\n",
       " '제발',\n",
       " '살려주세요',\n",
       " '만약',\n",
       " '신고한다면',\n",
       " '알아서',\n",
       " '생각해',\n",
       " '알겠어',\n",
       " '?',\n",
       " '!',\n",
       " '알았어요',\n",
       " '신고',\n",
       " '안할테니',\n",
       " '살려만주세요',\n",
       " '지켜볼거야',\n",
       " '꺼져',\n",
       " '!']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 확인\n",
    "conversation[1998].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[225, 94, 56, 99, 96]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 세기\n",
    "temp = list(map(lambda x : len(x.split()), conversation))\n",
    "temp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 시각화 - histplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH = 200 일때: 98.96 %\n",
      "MAX_LENGTH = 100 일때: 75.71 %\n",
      "MAX_LENGTH = 50 일때: 20.88 %\n"
     ]
    }
   ],
   "source": [
    "print(f'MAX_LENGTH = 200 일때: {np.array([True if x <= 200 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 100 일때: {np.array([True if x <= 100 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 50 일때: {np.array([True if x <= 50 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 200\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 초과하는 샘플은 데이터 자르기, 패딩\n",
    "def tokenize_and_filter(inputs):\n",
    "  tokenized_inputs = list()\n",
    "  \n",
    "  for sentence in inputs:\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tokenizer.encode(sentence)\n",
    "\n",
    "    # 최대 길이 200 까지만 데이터셋으로 사용\n",
    "    if len(sentence) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence)\n",
    "    \n",
    "    else:\n",
    "      tokenized_inputs.append(sentence[:MAX_LENGTH])\n",
    "  \n",
    "  # 최대 길이 200으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 2039\n",
      "필터링 후의 대화 샘플 개수: 8543\n"
     ]
    }
   ],
   "source": [
    "conversation = tokenize_and_filter(conversation)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 대화 샘플 개수: {}'.format(len(conversation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 - transformer 인코딩 모델 밑바닥부터 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "# 멀티 헤드 어텐션 구현하기\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# 패딩 마스크 구현 함수\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "#   attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "#   attention = tf.keras.layers.LayerNormalization(\n",
    "#       epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "#   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "#   outputs = tf.keras.layers.LayerNormalization(\n",
    "#       epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 인코더 생성하기\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  outputs = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "#   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더만 구성하기\n",
    "def my_encoder(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"my_encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # Global Average Pooling 적용 (or Max Pooling 가능)\n",
    "  outputs = tf.keras.layers.GlobalMaxPooling1D()(enc_outputs)\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(256, activation=\"relu\", name='dense1')(outputs)\n",
    "#   outputs = tf.keras.layers.Dropout(0.3)(outputs)  # 🔥 드롭아웃 추가 (30%)\n",
    "  outputs = tf.keras.layers.Dense(128, activation=\"relu\", name='dense2')(outputs)\n",
    "#   outputs = tf.keras.layers.Dropout(0.3)(outputs)  # 🔥 드롭아웃 추가 (30%)\n",
    "  outputs = tf.keras.layers.Dense(units=5, activation=\"softmax\", name='outputs')(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 128)    656512      inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 256)          33024       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128)          32896       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            645         dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 723,077\n",
      "Trainable params: 723,077\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성하기\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = my_encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# EarlyStopping & ModelCheckpoint 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model\", monitor='val_loss', save_best_only=True, mode='max', verbose=1, save_format=\"tf\", save_weights_only=True)\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer='adamax', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation = val_df['conversation'].apply(preprocess_sentence)\n",
    "# conversation = tokenize_and_filter(conversation)\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((\n",
    "# {'inputs': conversation},  # 입력 데이터\n",
    "# {'outputs': val_df['class_encoded'].values}  # 출력 데이터 (라벨)\n",
    "# ))\n",
    "\n",
    "# dataset = dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X, y 추출\n",
    "\n",
    "# # X와 y 리스트 생성\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "\n",
    "# # test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "# for x, y in dataset:\n",
    "#     X_train.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "#     y_train.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# # 리스트를 NumPy 배열로 변환\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# y_train[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 600\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# def get_dataset(data):\n",
    "#     conversation = data['conversation'].apply(preprocess_sentence)\n",
    "#     conversation = tokenize_and_filter(conversation)\n",
    "\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     {'inputs': conversation},  # 입력 데이터\n",
    "#     {'outputs': data['class_encoded'].values}  # 출력 데이터 (라벨)\n",
    "#     ))\n",
    "    \n",
    "#     dataset = dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "#     return dataset\n",
    "\n",
    "def get_dataset(data):\n",
    "    conversation = data['conversation'].apply(preprocess_sentence)\n",
    "    conversation = tokenize_and_filter(conversation)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': conversation},  # 입력 데이터\n",
    "    {'outputs': data['class_encoded'].values}  # 출력 데이터 (라벨)\n",
    "    ))\n",
    "    \n",
    "    dataset = dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(val_df)\n",
    "train_dataset2 = get_dataset(train_df)\n",
    "val_dataset = get_dataset(val_df)\n",
    "test_dataset = get_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6104 - accuracy: 0.1433 - val_loss: 1.5567 - val_accuracy: 0.3396\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.55669, saving model to best_model\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 1.5567 - accuracy: 0.3396 - val_loss: 1.4878 - val_accuracy: 0.3396\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.55669\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 1.4878 - accuracy: 0.3396 - val_loss: 1.4099 - val_accuracy: 0.4096\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.55669\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.4099 - accuracy: 0.4096 - val_loss: 1.3430 - val_accuracy: 0.4846\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.55669\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.3430 - accuracy: 0.4846 - val_loss: 1.2775 - val_accuracy: 0.4625\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.55669\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 1.2775 - accuracy: 0.4625 - val_loss: 1.2145 - val_accuracy: 0.4881\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.55669\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.2145 - accuracy: 0.4881 - val_loss: 1.1908 - val_accuracy: 0.5068\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.55669\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.1908 - accuracy: 0.5068 - val_loss: 1.1497 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.55669\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.1497 - accuracy: 0.5000 - val_loss: 1.1187 - val_accuracy: 0.5068\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.55669\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 1.1187 - accuracy: 0.5068 - val_loss: 1.1125 - val_accuracy: 0.5068\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.55669\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.1125 - accuracy: 0.5068 - val_loss: 1.0694 - val_accuracy: 0.5222\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.55669\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.0694 - accuracy: 0.5222 - val_loss: 1.0509 - val_accuracy: 0.5137\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.55669\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.0509 - accuracy: 0.5137 - val_loss: 1.0223 - val_accuracy: 0.5222\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.55669\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 1.0223 - accuracy: 0.5222 - val_loss: 0.9895 - val_accuracy: 0.5290\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.55669\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.9895 - accuracy: 0.5290 - val_loss: 0.9721 - val_accuracy: 0.5427\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.55669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.9721 - accuracy: 0.5427 - val_loss: 0.9405 - val_accuracy: 0.5495\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.55669\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.9405 - accuracy: 0.5495 - val_loss: 0.9264 - val_accuracy: 0.5563\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.55669\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.9264 - accuracy: 0.5563 - val_loss: 0.9071 - val_accuracy: 0.5836\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.55669\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.9071 - accuracy: 0.5836 - val_loss: 0.8925 - val_accuracy: 0.5904\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.55669\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.8925 - accuracy: 0.5904 - val_loss: 0.8829 - val_accuracy: 0.5717\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.55669\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.8829 - accuracy: 0.5717 - val_loss: 0.8722 - val_accuracy: 0.5819\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.55669\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.8722 - accuracy: 0.5819 - val_loss: 0.8616 - val_accuracy: 0.6314\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.55669\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.8616 - accuracy: 0.6314 - val_loss: 0.8522 - val_accuracy: 0.6229\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.55669\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.8522 - accuracy: 0.6229 - val_loss: 0.8402 - val_accuracy: 0.6177\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.55669\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.8402 - accuracy: 0.6177 - val_loss: 0.8268 - val_accuracy: 0.6553\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.55669\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.8268 - accuracy: 0.6553 - val_loss: 0.8104 - val_accuracy: 0.7099\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.55669\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.8104 - accuracy: 0.7099 - val_loss: 0.7901 - val_accuracy: 0.7082\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.55669\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.7901 - accuracy: 0.7082 - val_loss: 0.7664 - val_accuracy: 0.6826\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.55669\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.7664 - accuracy: 0.6826 - val_loss: 0.7377 - val_accuracy: 0.7321\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.55669\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.7377 - accuracy: 0.7321 - val_loss: 0.7043 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.55669\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.7043 - accuracy: 0.7389 - val_loss: 0.6744 - val_accuracy: 0.7611\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.55669\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.6744 - accuracy: 0.7611 - val_loss: 0.6407 - val_accuracy: 0.7543\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.55669\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.6407 - accuracy: 0.7543 - val_loss: 0.5967 - val_accuracy: 0.7918\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.55669\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.5967 - accuracy: 0.7918 - val_loss: 0.5567 - val_accuracy: 0.8003\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.55669\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.5567 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.8072\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.55669\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.5183 - accuracy: 0.8072 - val_loss: 0.4929 - val_accuracy: 0.8242\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.55669\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.4929 - accuracy: 0.8242 - val_loss: 0.4419 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.55669\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.4419 - accuracy: 0.8447 - val_loss: 0.3960 - val_accuracy: 0.8618\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.55669\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.3960 - accuracy: 0.8618 - val_loss: 0.3822 - val_accuracy: 0.8805\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.55669\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.3822 - accuracy: 0.8805 - val_loss: 0.3301 - val_accuracy: 0.8891\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.55669\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.3301 - accuracy: 0.8891 - val_loss: 0.2901 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.55669\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.2901 - accuracy: 0.9096 - val_loss: 0.2735 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.55669\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 444ms/step - loss: 0.2735 - accuracy: 0.9164 - val_loss: 0.2207 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.55669\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.2207 - accuracy: 0.9369 - val_loss: 0.1921 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.55669\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.1921 - accuracy: 0.9471 - val_loss: 0.1675 - val_accuracy: 0.9573\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.55669\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.1675 - accuracy: 0.9573 - val_loss: 0.1245 - val_accuracy: 0.9727\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.55669\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1245 - accuracy: 0.9727 - val_loss: 0.1047 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.55669\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1047 - accuracy: 0.9795 - val_loss: 0.0792 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.55669\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0792 - accuracy: 0.9881 - val_loss: 0.0575 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.55669\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0575 - accuracy: 0.9898 - val_loss: 0.0435 - val_accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.55669\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0435 - accuracy: 0.9983 - val_loss: 0.0298 - val_accuracy: 0.9983\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.55669\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0298 - accuracy: 0.9983 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.55669\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.55669\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.55669\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.55669\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.55669\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.55669\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.55669\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.55669\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.55669\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.55669\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.55669\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.55669\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.8341e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.55669\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 9.8341e-04 - accuracy: 1.0000 - val_loss: 8.6568e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.55669\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 8.6568e-04 - accuracy: 1.0000 - val_loss: 8.2918e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.55669\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 8.2918e-04 - accuracy: 1.0000 - val_loss: 7.9462e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.55669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 7.9462e-04 - accuracy: 1.0000 - val_loss: 7.2255e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.55669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 7.2255e-04 - accuracy: 1.0000 - val_loss: 6.1597e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.55669\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 6.1597e-04 - accuracy: 1.0000 - val_loss: 5.0224e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.55669\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 5.0224e-04 - accuracy: 1.0000 - val_loss: 4.0681e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.55669\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 4.0681e-04 - accuracy: 1.0000 - val_loss: 3.4048e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.55669\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.4048e-04 - accuracy: 1.0000 - val_loss: 3.0144e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.55669\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 3.0144e-04 - accuracy: 1.0000 - val_loss: 2.8125e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.55669\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.8125e-04 - accuracy: 1.0000 - val_loss: 2.7066e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.55669\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.7066e-04 - accuracy: 1.0000 - val_loss: 2.6118e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.55669\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.6118e-04 - accuracy: 1.0000 - val_loss: 2.4717e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.55669\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 2.4717e-04 - accuracy: 1.0000 - val_loss: 2.2757e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.55669\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 2.2757e-04 - accuracy: 1.0000 - val_loss: 2.0491e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.55669\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 2.0491e-04 - accuracy: 1.0000 - val_loss: 1.8275e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.55669\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.8275e-04 - accuracy: 1.0000 - val_loss: 1.6338e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.55669\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 1.6338e-04 - accuracy: 1.0000 - val_loss: 1.4776e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.55669\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 1.4776e-04 - accuracy: 1.0000 - val_loss: 1.3583e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.55669\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 450ms/step - loss: 1.3583e-04 - accuracy: 1.0000 - val_loss: 1.2697e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.55669\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 1.2697e-04 - accuracy: 1.0000 - val_loss: 1.2052e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.55669\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.2052e-04 - accuracy: 1.0000 - val_loss: 1.1573e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.55669\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.1573e-04 - accuracy: 1.0000 - val_loss: 1.1180e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.55669\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.1180e-04 - accuracy: 1.0000 - val_loss: 1.0807e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.55669\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 1.0807e-04 - accuracy: 1.0000 - val_loss: 1.0420e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.55669\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 1.0420e-04 - accuracy: 1.0000 - val_loss: 1.0004e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.55669\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 1.0004e-04 - accuracy: 1.0000 - val_loss: 9.5603e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.55669\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 9.5603e-05 - accuracy: 1.0000 - val_loss: 9.1103e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.55669\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 9.1103e-05 - accuracy: 1.0000 - val_loss: 8.6570e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.55669\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 8.6570e-05 - accuracy: 1.0000 - val_loss: 8.2276e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.55669\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 8.2276e-05 - accuracy: 1.0000 - val_loss: 7.8284e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.55669\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 7.8284e-05 - accuracy: 1.0000 - val_loss: 7.4654e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.55669\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 7.4654e-05 - accuracy: 1.0000 - val_loss: 7.1399e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.55669\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 7.1399e-05 - accuracy: 1.0000 - val_loss: 6.8522e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.55669\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 6.8522e-05 - accuracy: 1.0000 - val_loss: 6.5978e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.55669\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 6.5978e-05 - accuracy: 1.0000 - val_loss: 6.3745e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.55669\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 학습 실행 (history 저장)\n",
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 학습 결과(history) 가져오기\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history.get('accuracy', history.history.get('acc'))  # 'accuracy' 또는 'acc' 키 확인\n",
    "val_acc = history.history.get('val_accuracy', history.history.get('val_acc'))  # 'val_accuracy' 또는 'val_acc' 키 확인\n",
    "\n",
    "# 에포크 값 생성\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Loss 그래프\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1819\n",
       "1    1753\n",
       "2    1743\n",
       "4    1623\n",
       "0    1605\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in train_dataset:\n",
    "    X_train.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_train.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "pd.value_counts(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1819\n",
       "1    1753\n",
       "2    1743\n",
       "4    1623\n",
       "0    1605\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in val_dataset:\n",
    "    X_val.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_val.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "pd.value_counts(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    194\n",
       "3    105\n",
       "1    103\n",
       "2    102\n",
       "0     82\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "pd.value_counts(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17672, 200)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 합치기\n",
    "temp = np.concatenate([X_train, X_val, X_test], axis=0)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9128, 200)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 중복값 확인(데이터 누출 확인)\n",
    "np.unique(temp, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 20ms/step - loss: 0.0072 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007185528986155987, 0.9971906542778015]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (train_dataset을 사용)\n",
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 21ms/step - loss: 0.0072 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007185528986155987, 0.9971906542778015]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (train_dataset을 사용)\n",
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 20ms/step - loss: 0.0072 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007185528986155987, 0.9971906542778015]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (validation_dataset을 사용)\n",
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0654 - accuracy: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06541778147220612, 0.9812286496162415]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (test_dataset을 사용)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (586, 200)\n",
      "y_test shape: (586,)\n"
     ]
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 1, 4, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pred(X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = get_pred(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9512    0.9750        82\n",
      "           1     0.9898    0.9417    0.9652       103\n",
      "           2     0.9808    1.0000    0.9903       102\n",
      "           3     0.9286    0.9905    0.9585       105\n",
      "           4     1.0000    1.0000    1.0000       194\n",
      "\n",
      "    accuracy                         0.9812       586\n",
      "   macro avg     0.9798    0.9767    0.9778       586\n",
      "weighted avg     0.9821    0.9812    0.9813       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 Submission 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  target\n",
       "0  t_000       1\n",
       "1  t_001       2\n",
       "2  t_002       2\n",
       "3  t_003       3\n",
       "4  t_004       1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_submission_df(model, test_df):\n",
    "    test_conversation = test_df['text'].apply(preprocess_sentence)\n",
    "    test_conversation = tokenize_and_filter(test_conversation)\n",
    "    \n",
    "    y_pred = get_pred(test_conversation)\n",
    "    \n",
    "    test_df['target'] = y_pred\n",
    "    test_df.drop(['text'], axis=1, inplace=True)\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "test_df = load_data(test_path)\n",
    "test_df = make_submission_df(model, test_df)\n",
    "test_df.to_csv('my_submission.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t_005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t_006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t_007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t_008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  target\n",
       "5  t_005       0\n",
       "6  t_006       0\n",
       "7  t_007       1\n",
       "8  t_008       3\n",
       "9  t_009       1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    168\n",
       "2    116\n",
       "1    113\n",
       "0     96\n",
       "4      7\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t_011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>t_027</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>t_057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>t_090</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>t_093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>t_274</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>t_397</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx  target\n",
       "11   t_011       4\n",
       "27   t_027       4\n",
       "57   t_057       4\n",
       "90   t_090       4\n",
       "93   t_093       4\n",
       "274  t_274       4\n",
       "397  t_397       4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['target']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
