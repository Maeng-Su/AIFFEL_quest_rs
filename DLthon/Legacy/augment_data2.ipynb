{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_438/3286253939.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_df1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrain_df3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_438/3286253939.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# train, test 데이터 불러오기\n",
    "\n",
    "train_path1 = './augment data/augmented_inserted_text_data.csv' # 필요에 따라 변경하세요.\n",
    "train_path2 = './augment data/augmented_replaced_text_data.csv' # 필요에 따라 변경하세요.\n",
    "train_path3 = './augment data/raw_data.csv' # 필요에 따라 변경하세요.\n",
    "test_path = './data/test.csv' # 필요에 따라 변경하세요.\n",
    "# train_normal_data_path = './data/일반대화 합성데이터(GPT-4o, AIhub 참고).csv'\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df1 = load_data(train_path1)\n",
    "train_df2 = load_data(train_path2)\n",
    "train_df3 = load_data(train_path3)\n",
    "test_df = load_data(test_path)\n",
    "# normal_df = load_data(train_normal_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_438/3913998314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df3' is not defined"
     ]
    }
   ],
   "source": [
    "train_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_438/2612092324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conversation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4846\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4846\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4846\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4846\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df3' is not defined"
     ]
    }
   ],
   "source": [
    "train_df3 = train_df3.drop_duplicates(subset=['conversation'])\n",
    "train_df3 = train_df3.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "val_df = train_df3.iloc[:4846//10, ]\n",
    "test_df = train_df3.iloc[4846//10:4846//10*2, ]\n",
    "train_df3 = train_df3.iloc[4846//10*2:, ]\n",
    "val_df.shape, test_df.shape, train_df3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "# train_df.shape, test_df.shape # , normal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11286, 5),\n",
       "    level_0      class  class_encoded  \\\n",
       " 0        0      협박 대화              0   \n",
       " 1        1      협박 대화              0   \n",
       " 2        2  기타 괴롭힘 대화              3   \n",
       " 3        3      갈취 대화              1   \n",
       " 4        4      갈취 대화              1   \n",
       " \n",
       "                                         conversation  index  \n",
       " 0  왜 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면...    NaN  \n",
       " 1  길동경찰서입니다. 9시 40분 마트에 폭발물을 하나 더 설치할거다.? 네? 똑바로 ...    NaN  \n",
       " 2  너 되게 귀여운거 알지? 나보다 키 작은 남자는 첨봤어. 그만해. 니들 놀리는거 진...    NaN  \n",
       " 3  어이 거기 예?? 너 말이야 너. 너 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘...    NaN  \n",
       " 4  저기요 혹시 날이 너무 많이 뜨겁잖아요? 저희 회사에서 지금 이 선크림 파는데 한 ...    NaN  )"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 와 normal 데이터 합치기\n",
    "def concat_train_normal(df_list):\n",
    "    train_df = pd.concat(df_list, ignore_index=True)\n",
    "#     train_df.drop(['idx'], axis=1, inplace=True)\n",
    "    train_df.reset_index(inplace=True)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "df_list = [train_df1, train_df2, train_df3]\n",
    "train_df = concat_train_normal(df_list)\n",
    "train_df.shape, train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>왜 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>길동경찰서입니다. 9시 40분 마트에 폭발물을 하나 더 설치할거다.? 네? 똑바로 ...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 키 작은 남자는 첨봤어. 그만해. 니들 놀리는거 진...</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어이 거기 예?? 너 말이야 너. 너 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>저기요 혹시 날이 너무 많이 뜨겁잖아요? 저희 회사에서 지금 이 선크림 파는데 한 ...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation      class  class_encoded\n",
       "0  왜 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면...      협박 대화              0\n",
       "1  길동경찰서입니다. 9시 40분 마트에 폭발물을 하나 더 설치할거다.? 네? 똑바로 ...      협박 대화              0\n",
       "2  너 되게 귀여운거 알지? 나보다 키 작은 남자는 첨봤어. 그만해. 니들 놀리는거 진...  기타 괴롭힘 대화              3\n",
       "3  어이 거기 예?? 너 말이야 너. 너 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘...      갈취 대화              1\n",
       "4  저기요 혹시 날이 너무 많이 뜨겁잖아요? 저희 회사에서 지금 이 선크림 파는데 한 ...      갈취 대화              1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['conversation', 'class', 'class_encoded']]\n",
    "val_df = val_df[['conversation', 'class', 'class_encoded']]\n",
    "test_df = test_df[['conversation', 'class', 'class_encoded']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 클래스 숫자로 변환\n",
    "# def class_encoding(train_df, class_mapping):\n",
    "#     train_df['class_encoded'] = train_df['class'].replace(class_mapping)\n",
    "    \n",
    "#     return train_df\n",
    "\n",
    "# # 클래스 매핑 딕셔너리 정의\n",
    "# class_mapping = {\n",
    "#     \"협박 대화\": 0,\n",
    "#     \"갈취 대화\": 1,\n",
    "#     \"직장 내 괴롭힘 대화\": 2,\n",
    "#     \"기타 괴롭힘 대화\": 3 # ,\n",
    "# #     \"일반 대화\": 4\n",
    "# }\n",
    "\n",
    "# train_df = class_encoding(train_df, class_mapping)\n",
    "\n",
    "# # 변환된 데이터 확인\n",
    "# train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11286, 3), (1615, 3), (1615, 3))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11286, 3), (1615, 3), (1615, 3))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복된 'conversation' 제거\n",
    "train_df = train_df.drop_duplicates(subset=['conversation'])\n",
    "val_df = val_df.drop_duplicates(subset=['conversation'])\n",
    "test_df = test_df.drop_duplicates(subset=['conversation'])\n",
    "\n",
    "# 중복 제거 후 데이터 확인\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # 1️⃣ 먼저 데이터를 섞기\n",
    "# train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # 2️⃣ 60%: 훈련 데이터 분할\n",
    "# train_data, temp_data = train_test_split(train_df, test_size=0.4, random_state=42, stratify=train_df['class_encoded'])\n",
    "\n",
    "# # 3️⃣ 남은 40% 중 50%를 검증, 50%를 테스트로 나누기 (즉, 20%씩)\n",
    "# val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['class_encoded'])\n",
    "\n",
    "# # 4️⃣ 결과 확인\n",
    "# print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}, Test size: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 개행 문자(\"\\n\")를 공백으로 변환\n",
    "  sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "    \n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # ?.!, 앞뒤로 공백 추가\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence) # 연속된 공백 한개의 공백으로\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z\\u1100-\\u11FF\\uAC00-\\uD7AF.,?!]\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        왜 지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을...\n",
       "1        길동경찰서입니다 .  시   분 마트에 폭발물을 하나 더 설치할거다 . ? 네 ? ...\n",
       "2        너 되게 귀여운거 알지 ? 나보다 키 작은 남자는 첨봤어 . 그만해 . 니들 놀리는...\n",
       "3        어이 거기 예 ? ? 너 말이야 너 . 너 이리 오라고 무슨 일 . 너 옷 좋아보인...\n",
       "4        저기요 혹시 날이 너무 많이 뜨겁잖아요 ? 저희 회사에서 지금 이 선크림 파는데 한...\n",
       "                               ...                        \n",
       "11281    다음 주 목금 휴가 쓰면 완전 연휴 길더라 ? 와 내가 그렇게 쓰려다가 빠꾸당함 ....\n",
       "11282    그래도 가족들이 많이 믿어주고 그래서 열심히 할 수 있는 거 같으면서도 부담스럽기도...\n",
       "11283    시간 얼마 안남았어 알고 있습니다 . 시간 넘기면 안돼 노력 해보겠습니다 . 노력 ...\n",
       "11284    인정 그리고 난 결혼하면 고양이 키울 거라 너 비염 치료해야 해 안돼 고양이 강아지...\n",
       "11285    빌린돈 언제 갚을건데 조만간갚겟습니다  달만 시간을주세요 그건좀 곤란한데 지금 돈구...\n",
       "Name: conversation, Length: 11286, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = train_df['conversation'].apply(preprocess_sentence)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(conversation, target_vocab_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20684\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 1998번째 질문 샘플: [34, 8450, 476, 4691, 1471, 1, 16, 3852, 2, 106, 1910, 666, 1797, 12941, 15, 9893, 2032, 9, 19385, 27, 4987, 137, 1, 134, 2062, 837, 1, 66, 53, 2032, 699, 539, 53, 7375, 446, 2, 11672, 44, 2940, 17774, 7917, 69, 1, 34, 534, 20663, 20556, 20609, 44, 989, 14325, 36, 5334, 1, 3369, 1, 147, 9216, 2870, 979, 6332, 876, 2858, 1, 335, 17429, 493, 9315, 1, 90, 10139, 2714, 5098, 405, 201, 1595, 3126, 66, 82, 47, 6988, 1775, 233, 3026, 2849, 9772, 1, 1752, 2, 544, 26, 12818, 20458, 5863, 1, 498, 1, 34, 430, 8324, 30, 337, 9459, 288, 1325, 8754, 1767, 1, 7274, 25]\n"
     ]
    }
   ],
   "source": [
    "# 1998번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 1998번째 질문 샘플: {}'.format(tokenizer.encode(conversation[1998])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그',\n",
       " '학생이',\n",
       " '잠깐',\n",
       " '이리로',\n",
       " '와봐',\n",
       " '.',\n",
       " '왜',\n",
       " '그러시죠',\n",
       " '?',\n",
       " '요즘',\n",
       " '부모들은',\n",
       " '어린',\n",
       " '애들한테도',\n",
       " '명품',\n",
       " '옷을',\n",
       " '좀',\n",
       " '사준다고',\n",
       " '하더니',\n",
       " '.',\n",
       " '진짜였군',\n",
       " '.',\n",
       " '제가',\n",
       " '무슨',\n",
       " '옷을',\n",
       " '입든',\n",
       " '무슨',\n",
       " '상관이에요',\n",
       " '?',\n",
       " '학생들은',\n",
       " '학생답게',\n",
       " '다녀야지',\n",
       " '.',\n",
       " '그',\n",
       " '재킷은',\n",
       " '오늘부로',\n",
       " '내',\n",
       " '거다',\n",
       " '.',\n",
       " '싫어요',\n",
       " '.',\n",
       " '제',\n",
       " '생일선물로',\n",
       " '겨우',\n",
       " '받은',\n",
       " '옷이란',\n",
       " '말이에요',\n",
       " '.',\n",
       " '일을',\n",
       " '복잡하게',\n",
       " '되게',\n",
       " '만드네',\n",
       " '.',\n",
       " '이렇게',\n",
       " '험한',\n",
       " '꼴',\n",
       " '당하고',\n",
       " '싶어',\n",
       " '?',\n",
       " '.',\n",
       " '아뇨',\n",
       " '그치만',\n",
       " '제가',\n",
       " '정말',\n",
       " '많이',\n",
       " '아끼는',\n",
       " '옷인데',\n",
       " '이번만',\n",
       " '봐주시면',\n",
       " '.',\n",
       " '안될까요',\n",
       " '?',\n",
       " '좋아',\n",
       " '그럼',\n",
       " '인심',\n",
       " '썼다',\n",
       " '.',\n",
       " '그럼',\n",
       " '.',\n",
       " '그',\n",
       " '옷',\n",
       " '대신',\n",
       " '만원',\n",
       " '가져와봐',\n",
       " '.',\n",
       " '.',\n",
       " '엄마한테',\n",
       " '문자할게요',\n",
       " '.',\n",
       " '잠시만요',\n",
       " '.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 확인\n",
    "conversation[1998].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 56, 73, 48, 156]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 세기\n",
    "temp = list(map(lambda x : len(x.split()), conversation))\n",
    "temp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 시각화 - histplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH = 200 일때: 95.53 %\n",
      "MAX_LENGTH = 100 일때: 69.48 %\n",
      "MAX_LENGTH = 50 일때: 23.10 %\n"
     ]
    }
   ],
   "source": [
    "print(f'MAX_LENGTH = 200 일때: {np.array([True if x <= 200 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 100 일때: {np.array([True if x <= 100 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 50 일때: {np.array([True if x <= 50 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 100\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 초과하는 샘플은 데이터 자르기, 패딩\n",
    "def tokenize_and_filter(inputs):\n",
    "  tokenized_inputs = list()\n",
    "  \n",
    "  for sentence in inputs:\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tokenizer.encode(sentence)\n",
    "\n",
    "    # 최대 길이 200 까지만 데이터셋으로 사용\n",
    "    if len(sentence) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence)\n",
    "    \n",
    "    else:\n",
    "      tokenized_inputs.append(sentence[:MAX_LENGTH])\n",
    "  \n",
    "  # 최대 길이 200으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 20684\n",
      "필터링 후의 대화 샘플 개수: 11286\n"
     ]
    }
   ],
   "source": [
    "conversation = tokenize_and_filter(conversation)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 대화 샘플 개수: {}'.format(len(conversation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 - transformer 인코딩 모델 밑바닥부터 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "# 멀티 헤드 어텐션 구현하기\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# 패딩 마스크 구현 함수\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 인코더 생성하기\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더만 구성하기\n",
    "def my_encoder(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"my_encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # Global Average Pooling 적용 (or Max Pooling 가능)\n",
    "  outputs = tf.keras.layers.GlobalMaxPooling1D()(enc_outputs)\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(256, activation=\"relu\", name='dense1')(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(0.3)(outputs)  # 🔥 드롭아웃 추가 (30%)\n",
    "  outputs = tf.keras.layers.Dense(128, activation=\"relu\", name='dense2')(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(0.3)(outputs)  # 🔥 드롭아웃 추가 (30%)\n",
    "  outputs = tf.keras.layers.Dense(units=5, activation=\"softmax\", name='outputs')(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    6349312     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 256)          65792       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128)          32896       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            645         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,448,645\n",
      "Trainable params: 6,448,645\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성하기\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = my_encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# EarlyStopping & ModelCheckpoint 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model\", monitor='val_loss', save_best_only=True, mode='max', verbose=1, save_format=\"tf\", save_weights_only=True)\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "def get_dataset(data):\n",
    "    conversation = data['conversation'].apply(preprocess_sentence)\n",
    "    conversation = tokenize_and_filter(conversation)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': conversation},  # 입력 데이터\n",
    "    {'outputs': data['class_encoded'].values}  # 출력 데이터 (라벨)\n",
    "    ))\n",
    "    \n",
    "    dataset = dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(train_df)\n",
    "val_dataset = get_dataset(val_df)\n",
    "test_dataset = get_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "177/177 [==============================] - 9s 40ms/step - loss: 2.0446 - accuracy: 0.2058 - val_loss: 1.5759 - val_accuracy: 0.3573\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.57589, saving model to best_model\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 1.7155 - accuracy: 0.2051 - val_loss: 1.5843 - val_accuracy: 0.2372\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.57589 to 1.58427, saving model to best_model\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 1.6776 - accuracy: 0.2348 - val_loss: 1.5636 - val_accuracy: 0.3325\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58427\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 1.4360 - accuracy: 0.3416 - val_loss: 1.1954 - val_accuracy: 0.3517\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58427\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 1.1410 - accuracy: 0.4501 - val_loss: 0.9418 - val_accuracy: 0.5820\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58427\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.7674 - accuracy: 0.6940 - val_loss: 0.3497 - val_accuracy: 0.8947\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58427\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.2525 - accuracy: 0.9162 - val_loss: 0.1105 - val_accuracy: 0.9703\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.58427\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.1167 - accuracy: 0.9661 - val_loss: 0.0260 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.58427\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.0562 - accuracy: 0.9857 - val_loss: 0.0323 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.58427\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.0497 - accuracy: 0.9871 - val_loss: 0.0421 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.58427\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0706 - accuracy: 0.9825 - val_loss: 0.0681 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.58427\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.0305 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.58427\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0281 - accuracy: 0.9939 - val_loss: 0.0239 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.58427\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0284 - accuracy: 0.9948 - val_loss: 0.0056 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.58427\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.2062 - accuracy: 0.9662 - val_loss: 0.1415 - val_accuracy: 0.9703\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.58427\n",
      "Epoch 16/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0408 - accuracy: 0.9925 - val_loss: 0.0212 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.58427\n",
      "Epoch 17/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.0241 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.58427\n",
      "Epoch 18/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0246 - accuracy: 0.9951 - val_loss: 0.0525 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.58427\n",
      "Epoch 19/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.3032 - accuracy: 0.9572 - val_loss: 0.1271 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.58427\n",
      "Epoch 20/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0567 - accuracy: 0.9908 - val_loss: 0.0493 - val_accuracy: 0.9901\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.58427\n",
      "Epoch 21/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0300 - accuracy: 0.9934 - val_loss: 0.0356 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.58427\n",
      "Epoch 22/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0284 - accuracy: 0.9954 - val_loss: 0.0501 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.58427\n",
      "Epoch 23/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.2030 - accuracy: 0.9654 - val_loss: 0.0657 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.58427\n",
      "Epoch 24/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0209 - accuracy: 0.9960 - val_loss: 0.0449 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.58427\n",
      "Epoch 25/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.1099 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.58427\n",
      "Epoch 26/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.0364 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.58427\n",
      "Epoch 27/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.0897 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.58427\n",
      "Epoch 28/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0607 - accuracy: 0.9915 - val_loss: 0.0174 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.58427\n",
      "Epoch 29/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.1492 - accuracy: 0.9780 - val_loss: 0.0795 - val_accuracy: 0.9765\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.58427\n",
      "Epoch 30/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0281 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.58427\n",
      "Epoch 31/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0529 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.58427\n",
      "Epoch 32/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 0.0988 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.58427\n",
      "Epoch 33/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0345 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.58427\n",
      "Epoch 34/100\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0317 - val_accuracy: 0.9963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.58427\n",
      "Epoch 00034: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 학습 실행 (history 저장)\n",
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 학습 결과(history) 가져오기\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history.get('accuracy', history.history.get('acc'))  # 'accuracy' 또는 'acc' 키 확인\n",
    "val_acc = history.history.get('val_accuracy', history.history.get('val_acc'))  # 'val_accuracy' 또는 'val_acc' 키 확인\n",
    "\n",
    "# 에포크 값 생성\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Loss 그래프\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2344\n",
       "4    2316\n",
       "1    2286\n",
       "2    2236\n",
       "0    2104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in train_dataset:\n",
    "    X_train.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_train.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "pd.value_counts(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    383\n",
       "2    351\n",
       "4    302\n",
       "1    299\n",
       "0    280\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in val_dataset:\n",
    "    X_val.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_val.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "pd.value_counts(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    360\n",
       "1    334\n",
       "2    323\n",
       "3    306\n",
       "0    292\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "pd.value_counts(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14516, 100)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 합치기\n",
    "temp = np.concatenate([X_train, X_val, X_test], axis=0)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14515, 100)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 중복값 확인(데이터 누출 확인)\n",
    "np.unique(temp, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 2s 13ms/step - loss: 0.0060 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006037597078830004, 0.999291181564331]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (train_dataset을 사용)\n",
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005553610622882843, 0.998142421245575]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (validation_dataset을 사용)\n",
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.014207848347723484, 0.9975232481956482]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (test_dataset을 사용)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (1615, 100)\n",
      "y_test shape: (1615,)\n"
     ]
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, 2, 4])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pred(X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = get_pred(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9966    0.9966    0.9966       292\n",
      "           1     1.0000    0.9970    0.9985       334\n",
      "           2     1.0000    0.9938    0.9969       323\n",
      "           3     0.9903    1.0000    0.9951       306\n",
      "           4     1.0000    1.0000    1.0000       360\n",
      "\n",
      "    accuracy                         0.9975      1615\n",
      "   macro avg     0.9974    0.9975    0.9974      1615\n",
      "weighted avg     0.9975    0.9975    0.9975      1615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 Submission 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  target\n",
       "0  t_000       1\n",
       "1  t_001       2\n",
       "2  t_002       2\n",
       "3  t_003       2\n",
       "4  t_004       3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_submission_df(model, test_df):\n",
    "    test_conversation = test_df['text'].apply(preprocess_sentence)\n",
    "    test_conversation = tokenize_and_filter(test_conversation)\n",
    "    \n",
    "    y_pred = get_pred(test_conversation)\n",
    "    \n",
    "    test_df['target'] = y_pred\n",
    "    test_df.drop(['text'], axis=1, inplace=True)\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "test_df = make_submission_df(model, test_df)\n",
    "test_df.to_csv('my_submission.csv', index=False)\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
